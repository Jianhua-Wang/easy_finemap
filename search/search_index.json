{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"easyfinemap \u00b6 user-friendly pipeline for GWAS fine-mapping Documentation: https://Jianhua-Wang.github.io/easyfinemap GitHub: https://github.com/Jianhua-Wang/easyfinemap PyPI: https://pypi.org/project/easyfinemap/ Free software: MIT Features \u00b6 TODO: Standardize input summary statistics TODO: Identify independent loci by distance, LD clumping, or conditional analysis TODO: Fine-mapping with or without LD reference Credits \u00b6 This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Index"},{"location":"#easyfinemap","text":"user-friendly pipeline for GWAS fine-mapping Documentation: https://Jianhua-Wang.github.io/easyfinemap GitHub: https://github.com/Jianhua-Wang/easyfinemap PyPI: https://pypi.org/project/easyfinemap/ Free software: MIT","title":"easyfinemap"},{"location":"#features","text":"TODO: Standardize input summary statistics TODO: Identify independent loci by distance, LD clumping, or conditional analysis TODO: Fine-mapping with or without LD reference","title":"Features"},{"location":"#credits","text":"This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.","title":"Credits"},{"location":"api/","text":"Top-level package for easy_finemap. cli \u00b6 Console script for easy_finemap. validate_ldref ( ldref_path = typer . Argument ( Ellipsis , help = 'The path to the LD reference file.' ), outprefix = typer . Argument ( Ellipsis , help = 'The output prefix.' ), file_type = typer . Option ( 'plink' , '--file-type' , '-f' , help = 'The file type of the LD reference file.' ), mac = typer . Option ( 10 , '--mac' , '-m' , help = 'The minor allele count threshold.' ), threads = typer . Option ( 1 , '--threads' , '-t' , help = 'The number of threads.' )) \u00b6 Validate the LD reference file. Source code in easyfinemap/cli.py 19 20 21 22 23 24 25 26 27 28 29 @app . command () def validate_ldref ( ldref_path : str = typer . Argument ( ... , help = \"The path to the LD reference file.\" ), outprefix : str = typer . Argument ( ... , help = \"The output prefix.\" ), file_type : str = typer . Option ( \"plink\" , \"--file-type\" , \"-f\" , help = \"The file type of the LD reference file.\" ), mac : int = typer . Option ( 10 , \"--mac\" , \"-m\" , help = \"The minor allele count threshold.\" ), threads : int = typer . Option ( 1 , \"--threads\" , \"-t\" , help = \"The number of threads.\" ), ) -> None : \"\"\"Validate the LD reference file.\"\"\" ld = LDRef () ld . valid ( ldref_path , outprefix , file_type , mac , threads ) validate_sumstats ( sumstats_path = typer . Argument ( Ellipsis , help = 'The path to the GWAS summary statistics file.' ), output = typer . Argument ( Ellipsis , help = 'The output prefix.' )) \u00b6 Validate the GWAS summary statistics file. Source code in easyfinemap/cli.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @app . command () def validate_sumstats ( sumstats_path : Path = typer . Argument ( ... , help = \"The path to the GWAS summary statistics file.\" ), output : Path = typer . Argument ( ... , help = \"The output prefix.\" ), ) -> None : \"\"\"Validate the GWAS summary statistics file.\"\"\" if sumstats_path . exists (): sumstats = pd . read_csv ( sumstats_path , sep = \" \\t \" ) typer . echo ( f \"Loaded { sumstats_path } successfully.\" ) typer . echo ( f \"Number of SNPs: { sumstats . shape [ 0 ] } \" ) typer . echo ( f \"Number of columns: { sumstats . shape [ 1 ] } \" ) typer . echo ( f \"Columns: { list ( sumstats . columns ) } \" ) valid_sumstats = SumStat ( sumstats ) valid_sumstats = valid_sumstats . standarize () if output . suffix == \".gz\" : valid_sumstats . to_csv ( output , sep = \" \\t \" , index = False , compression = \"gzip\" ) else : valid_sumstats . to_csv ( output , sep = \" \\t \" , index = False ) typer . echo ( f \"Saved the validated summary statistics to { output } .\" ) else : typer . echo ( f \"Could not find { sumstats_path } .\" ) raise FileNotFoundError ( f \"Could not find { sumstats_path } .\" ) constant \u00b6 Define constants used in the package. ColName \u00b6 Define column names. easyfinemap \u00b6 Main module. EasyFinemap () \u00b6 Bases: object Main class. Source code in easyfinemap/easyfinemap.py 9 10 11 def __init__ ( self ): \"\"\"Initialize.\"\"\" self . logger = logging . getLogger ( __name__ ) run () \u00b6 Run the program. Source code in easyfinemap/easyfinemap.py 13 14 15 def run ( self ): \"\"\"Run the program.\"\"\" self . logger . info ( \"Running the program\" ) ldref \u00b6 Prepare LD reference for easyfinemap. validate the LD reference. 1.1. remove duplicate SNPs. 1.2. make SNP names unique, chr-bp-sorted(EA,NEA). TODO: 1. intersect the significant snps with the LD reference. TODO: 2. make a plink file from the intersected snps. TODO: 3. calculate LD matrix from the plink file. LDRef ( log_level = 'DEBUG' ) \u00b6 Prepare LD reference for easyfinemap. Parameters: Name Type Description Default ldref_path str The path to the LD reference file. required file_type str , optional The file type of the LD reference file, by default \"plink\" TODO: support other file types, e.g. vcf. required log_level str , optional The log level, by default \"DEBUG\" 'DEBUG' Source code in easyfinemap/ldref.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , log_level : str = \"DEBUG\" ): \"\"\" Initialize the LDRef class. Parameters ---------- ldref_path : str The path to the LD reference file. file_type : str, optional The file type of the LD reference file, by default \"plink\" TODO: support other file types, e.g. vcf. log_level : str, optional The log level, by default \"DEBUG\" \"\"\" self . logger = logging . getLogger ( \"LDRef\" ) self . logger . setLevel ( log_level ) self . plink = Tools () . plink self . tmp_root = Path . cwd () / \"tmp\" / \"ldref\" if not self . tmp_root . exists (): self . tmp_root . mkdir ( parents = True ) self . temp_dir = tempfile . mkdtemp ( dir = self . tmp_root ) self . logger . debug ( f \"LDRef temp dir: { self . temp_dir } \" ) self . temp_dir_path = Path ( self . temp_dir ) clean ( inprefix , outprefix = None , mac = 10 ) \u00b6 Clean the extracted LD reference. Remove duplicated snps. Make SNP names unique, chr-bp-sorted(EA,NEA). Parameters: Name Type Description Default prefix str The prefix of the extracted LD reference. required outprefix str , optional The prefix of the cleaned LD reference, by default None If None, the cleaned LD reference will be saved to the same directory as the extracted LD reference. None mac int , optional The minor allele count threshold, by default 10 SNPs with MAC < mac will be removed. 10 Returns: Type Description None Source code in easyfinemap/ldref.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def clean ( self , inprefix : str , outprefix : Optional [ str ] = None , mac : int = 10 ) -> None : \"\"\" Clean the extracted LD reference. 1. Remove duplicated snps. 2. Make SNP names unique, chr-bp-sorted(EA,NEA). Parameters ---------- prefix : str The prefix of the extracted LD reference. outprefix : str, optional The prefix of the cleaned LD reference, by default None If None, the cleaned LD reference will be saved to the same directory as the extracted LD reference. mac : int, optional The minor allele count threshold, by default 10 SNPs with MAC < mac will be removed. Returns ------- None \"\"\" prefix = f \" { self . temp_dir_path } / { inprefix . split ( '/' )[ - 1 ] } \" bim_file = f \" { inprefix } .bim\" bim = pd . read_csv ( bim_file , sep = \" \\t \" , names = [ ColName . CHR , ColName . RSID , \"cM\" , ColName . BP , ColName . EA , ColName . NEA ] ) bim [ ColName . RSID ] = bim . index # use number as rsid, make sure it is unique bim . to_csv ( f \" { prefix } .bim\" , sep = \" \\t \" , index = False , header = False ) if mac <= 0 : raise ValueError ( f \"mac should be > 0, got { mac } .\" ) cmd = [ self . plink , \"--bed\" , f \" { inprefix } .bed\" , \"--fam\" , f \" { inprefix } .fam\" , \"--bim\" , f \" { prefix } .bim\" , \"--keep-allele-order\" , \"--list-duplicate-vars\" , \"ids-only\" , \"suppress-first\" , \"--out\" , f \" { prefix } \" , ] res = run ( cmd , stdout = PIPE , stderr = PIPE , universal_newlines = True ) self . logger . debug ( ' ' . join ( cmd )) cmd = [ self . plink , \"--bed\" , f \" { inprefix } .bed\" , \"--fam\" , f \" { inprefix } .fam\" , \"--bim\" , f \" { prefix } .bim\" , \"--exclude\" , f \" { prefix } .dupvar\" , \"--mac\" , str ( mac ), \"--keep-allele-order\" , \"--make-bed\" , \"--out\" , f \" { prefix } .clean\" , ] self . logger . debug ( ' ' . join ( cmd )) res = run ( cmd , stdout = PIPE , stderr = PIPE , universal_newlines = True ) if res . returncode != 0 : self . logger . error ( res . stderr ) raise RuntimeError ( res . stderr ) rmdup_bim = pd . read_csv ( f \" { prefix } .clean.bim\" , delim_whitespace = True , names = [ ColName . CHR , ColName . RSID , \"cM\" , ColName . BP , ColName . EA , ColName . NEA ], ) rmdup_bim = make_SNPID_unique ( rmdup_bim , replace_rsIDcol = True , remove_duplicates = False ) rmdup_bim . to_csv ( f \" { prefix } .clean.bim\" , sep = \" \\t \" , index = False , header = False ) if outprefix is not None : shutil . move ( f \" { prefix } .clean.bed\" , f \" { outprefix } .bed\" ) shutil . move ( f \" { prefix } .clean.bim\" , f \" { outprefix } .bim\" ) shutil . move ( f \" { prefix } .clean.fam\" , f \" { outprefix } .fam\" ) extract ( inprefix , outprefix , chrom , start = None , end = None , mac = 10 ) \u00b6 Extract the genotypes of given region from the LD reference. Parameters: Name Type Description Default inprefix str The input prefix. required outprefix str The output prefix. required chrom int The chromosome number. required start int , optional The start position, by default None None end int , optional The end position, by default None None mac int The minor allele count threshold, by default 10 10 Returns: Type Description None Source code in easyfinemap/ldref.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 def extract ( self , inprefix : str , outprefix : str , chrom : int , start : Optional [ int ] = None , end : Optional [ int ] = None , mac : int = 10 , ) -> None : \"\"\" Extract the genotypes of given region from the LD reference. Parameters ---------- inprefix : str The input prefix. outprefix : str The output prefix. chrom : int The chromosome number. start : int, optional The start position, by default None end : int, optional The end position, by default None mac: int, optional The minor allele count threshold, by default 10 Returns ------- None \"\"\" region_file = f \" { self . temp_dir } / { outprefix . split ( '/' )[ - 1 ] } .region\" if start is None : extract_cmd = [ \"--chr\" , str ( chrom )] else : with open ( region_file , \"w\" ) as f : f . write ( f \" { chrom } \\t { start } \\t { end } \\t region\" ) extract_cmd = [ \"--extract\" , \"range\" , region_file ] if \" {chrom} \" in inprefix : inprefix = inprefix . replace ( \" {chrom} \" , str ( chrom )) if not os . path . exists ( f \" { inprefix } .bed\" ): raise FileNotFoundError ( f \" { inprefix } .bed not found.\" ) cmd = [ self . plink , \"--bfile\" , inprefix , * extract_cmd , \"--keep-allele-order\" , \"--mac\" , str ( mac ), \"--make-bed\" , \"--out\" , outprefix , ] res = run ( cmd , stdout = PIPE , stderr = PIPE , universal_newlines = True ) self . logger . debug ( ' ' . join ( cmd )) self . logger . debug ( f \"extract chr { chrom } : { start } - { end } from { inprefix } \" ) if res . returncode != 0 : self . logger . error ( res . stderr ) self . logger . error ( f 'see log file: { outprefix } .log for details' ) raise RuntimeError ( res . stderr ) intersect ( sig_snps , use_ref_EAF = False ) \u00b6 Intersect the significant snps with the LD reference. Parameters: Name Type Description Default sig_snps pd . DataFrame The significant snps. required use_ref_EAF bool , optional Use the EAF in the LD reference, by default False False Returns: Type Description pd . DataFrame The intersected significant snps. Source code in easyfinemap/ldref.py 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 def intersect ( self , sig_snps : pd . DataFrame , use_ref_EAF : bool = False ) -> pd . DataFrame : \"\"\" Intersect the significant snps with the LD reference. Parameters ---------- sig_snps : pd.DataFrame The significant snps. use_ref_EAF : bool, optional Use the EAF in the LD reference, by default False Returns ------- pd.DataFrame The intersected significant snps. \"\"\" raise NotImplementedError valid ( ldref_path , outprefix , file_type = 'plink' , mac = 10 , threads = 1 ) \u00b6 Validate the LD reference file. TODO:1. format vcfs to plink files. 2. remove duplicated snps. 3. remove snps with MAC < mac. 4. make SNP names unique, chr-bp-sorted(EA,NEA). TODO:5. mark bim file with \"#easyfinemap validated\" flag in the first line. Parameters: Name Type Description Default ldref_path str The path to the LD reference file. required outprefix str The output prefix. required file_type str , optional The file type of the LD reference file, by default \"plink\" 'plink' mac int The minor allele count threshold, by default 10 10 Raises: Type Description ValueError If the file type is not supported. Returns: Type Description None Source code in easyfinemap/ldref.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def valid ( self , ldref_path : str , outprefix : str , file_type : str = \"plink\" , mac : int = 10 , threads : int = 1 ) -> None : \"\"\" Validate the LD reference file. TODO:1. format vcfs to plink files. 2. remove duplicated snps. 3. remove snps with MAC < mac. 4. make SNP names unique, chr-bp-sorted(EA,NEA). TODO:5. mark bim file with \"#easyfinemap validated\" flag in the first line. Parameters ---------- ldref_path : str The path to the LD reference file. outprefix : str The output prefix. file_type : str, optional The file type of the LD reference file, by default \"plink\" mac: int, optional The minor allele count threshold, by default 10 Raises ------ ValueError If the file type is not supported. Returns ------- None \"\"\" if file_type == \"plink\" : self . file_type = file_type else : raise ValueError ( f \"Unsupported file type: { file_type } \" ) params : List [ List [ Union [ str , int ]]] = [[] for _ in range ( 3 )] for chrom in CHROMS : if \" {chrom} \" in ldref_path : inprefix = ldref_path . replace ( \" {chrom} \" , str ( chrom )) if not os . path . exists ( f \" { inprefix } .bed\" ): raise FileNotFoundError ( f \" { inprefix } .bed not found.\" ) else : params [ 0 ] . append ( inprefix ) params [ 1 ] . append ( f \" { outprefix } .chr { chrom } \" ) params [ 2 ] . append ( mac ) else : inprefix = ldref_path if not os . path . exists ( f \" { inprefix } .bed\" ): raise FileNotFoundError ( f \" { inprefix } .bed not found.\" ) else : intermed_prefix = f \" { self . temp_dir } / { outprefix . split ( '/' )[ - 1 ] } .chr { chrom } \" self . extract ( inprefix , intermed_prefix , chrom , mac = mac ) params [ 0 ] . append ( intermed_prefix ) params [ 1 ] . append ( f \" { outprefix } .chr { chrom } \" ) params [ 2 ] . append ( mac ) with Pool ( threads ) as p : p . map ( self . clean , * params ) loci \u00b6 Get the independent loci from the input file. support three approaches: 1. identify the independent lead snps by distance only, TODO:2. identify the independent lead snps by LD clumping, TODO:3. identify the independent lead snps by conditional analysis. than expand the independent lead snps to independent loci by given range. merge the overlapped independent loci (optional). indep_snps_by_conditional ( sig_df , ld_df , r2_threshold = 0.8 ) \u00b6 Identify the independent snps by conditional analysis. Source code in easyfinemap/loci.py 93 94 95 def indep_snps_by_conditional ( sig_df : pd . DataFrame , ld_df : pd . DataFrame , r2_threshold : float = 0.8 ) -> pd . DataFrame : \"\"\"Identify the independent snps by conditional analysis.\"\"\" raise NotImplementedError indep_snps_by_distance ( sig_df , distance = 500000 ) \u00b6 Identify the independent snps by distance only. Parameters: Name Type Description Default sig_df pd . DataFrame The significant snps. required distance int , optional The distance threshold, by default 1000000 500000 Returns: Type Description pd . DataFrame The independent snps. Source code in easyfinemap/loci.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def indep_snps_by_distance ( sig_df : pd . DataFrame , distance : int = 500000 ) -> pd . DataFrame : \"\"\" Identify the independent snps by distance only. Parameters ---------- sig_df : pd.DataFrame The significant snps. distance : int, optional The distance threshold, by default 1000000 Returns ------- pd.DataFrame The independent snps. \"\"\" sig_df . sort_values ( ColName . P , inplace = True ) lead_snp = [] while len ( sig_df ): lead_snp . append ( sig_df . iloc [[ 0 ]]) sig_df = sig_df [ ~ ( ( sig_df [ ColName . CHR ] == sig_df . iloc [ 0 ][ ColName . CHR ]) & ( sig_df [ ColName . BP ] >= sig_df . iloc [ 0 ][ ColName . BP ] - distance ) & ( sig_df [ ColName . BP ] <= sig_df . iloc [ 0 ][ ColName . BP ] + distance ) ) ] # type: ignore lead_snp = pd . concat ( lead_snp , axis = 0 , ignore_index = True ) return lead_snp indep_snps_by_ldclumping ( sig_df , ld_df , r2_threshold = 0.8 ) \u00b6 Identify the independent snps by LD clumping. Source code in easyfinemap/loci.py 88 89 90 def indep_snps_by_ldclumping ( sig_df : pd . DataFrame , ld_df : pd . DataFrame , r2_threshold : float = 0.8 ) -> pd . DataFrame : \"\"\"Identify the independent snps by LD clumping.\"\"\" raise NotImplementedError leadsnp2loci ( sig_df , range = 500000 , if_merge = True ) \u00b6 Expand the independent lead snps to independent loci by given range. Parameters: Name Type Description Default sig_df pd . DataFrame The independent lead snps. required range int , optional The range, by default 1000000 500000 if_merge bool , optional Whether merge the overlapped loci, by default True True Returns: Type Description pd . DataFrame The independent loci. Source code in easyfinemap/loci.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def leadsnp2loci ( sig_df : pd . DataFrame , range : int = 500000 , if_merge : bool = True ) -> pd . DataFrame : \"\"\" Expand the independent lead snps to independent loci by given range. Parameters ---------- sig_df : pd.DataFrame The independent lead snps. range : int, optional The range, by default 1000000 if_merge : bool, optional Whether merge the overlapped loci, by default True Returns ------- pd.DataFrame The independent loci. \"\"\" loci_df = sig_df . copy () loci_df = make_SNPID_unique ( loci_df ) loci_df = loci_df [[ ColName . CHR , ColName . BP , ColName . P , ColName . SNPID ]] loci_df . columns = [ ColName . CHR , ColName . LEAD_SNP_BP , ColName . LEAD_SNP_P , ColName . LEAD_SNP ] # type: ignore loci_df [ ColName . START ] = loci_df [ ColName . LEAD_SNP_BP ] - range loci_df [ ColName . START ] = loci_df [ ColName . START ] . apply ( lambda x : 0 if x < 0 else x ) loci_df [ ColName . END ] = loci_df [ ColName . LEAD_SNP_BP ] + range loci_df = loci_df [ ColName . loci_cols ] . copy () if if_merge : loci_df = merge_overlapped_loci ( loci_df ) return loci_df merge_overlapped_loci ( loci_df ) \u00b6 Merge the overlapped loci. More details: https://stackoverflow.com/questions/57882621/efficient-merge-overlapping-intervals-in-same-pandas- dataframe-with-start-and-fi Parameters: Name Type Description Default loci_df pd . DataFrame The independent loci. required Returns: Type Description pd . DataFrame The merged independent loci. Source code in easyfinemap/loci.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def merge_overlapped_loci ( loci_df : pd . DataFrame ): \"\"\" Merge the overlapped loci. More details: https://stackoverflow.com/questions/57882621/efficient-merge-overlapping-intervals-in-same-pandas-\\ dataframe-with-start-and-fi Parameters ---------- loci_df : pd.DataFrame The independent loci. Returns ------- pd.DataFrame The merged independent loci. \"\"\" merged_loci = loci_df . copy () merged_loci . sort_values ([ ColName . CHR , ColName . START , ColName . END ], inplace = True ) merged_loci [ 'no_overlap' ] = merged_loci [ ColName . START ] > merged_loci [ ColName . END ] . shift () . cummax () merged_loci [ 'diff_chr' ] = merged_loci [ ColName . CHR ] != merged_loci [ ColName . CHR ] . shift () merged_loci [ \"break\" ] = merged_loci [ \"no_overlap\" ] | merged_loci [ 'diff_chr' ] merged_loci [ 'group' ] = merged_loci [ 'break' ] . cumsum () merged_loci = merged_loci . sort_values ([ 'group' , ColName . LEAD_SNP_P ], ascending = True ) agg_func = {} for col in loci_df . columns : if col == ColName . START : agg_func [ col ] = 'min' elif col == ColName . END : agg_func [ col ] = 'max' else : agg_func [ col ] = 'first' result = merged_loci . groupby ( \"group\" ) . agg ( agg_func ) result . reset_index ( drop = True , inplace = True ) return result logger \u00b6 Define custom logger. sumstat \u00b6 Standarize summary statistics for use with EasyFINEMAP. SumStat ( * args , ** kwargs ) \u00b6 Bases: pd . DataFrame extension of pd.Dataframe for standarize summary statistics. Source code in easyfinemap/sumstat.py 16 17 18 19 20 def __init__ ( self , * args , ** kwargs ): \"\"\"Initialize the SumstatAccessor class.\"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"Sumstat\" ) self . logger . setLevel ( \"DEBUG\" ) check_beta () \u00b6 Check if beta is valid. Source code in easyfinemap/sumstat.py 90 91 92 93 94 95 def check_beta ( self ): \"\"\"Check if beta is valid.\"\"\" self [ ColName . BETA ] = pd . to_numeric ( self [ ColName . BETA ], errors = \"coerce\" ) self = self [ self [ ColName . BETA ] . notnull ()] self [ ColName . BETA ] = self [ ColName . BETA ] . astype ( float ) return self check_bp () \u00b6 Check if bp is a valid integer. Source code in easyfinemap/sumstat.py 66 67 68 69 70 71 72 def check_bp ( self ): \"\"\"Check if bp is a valid integer.\"\"\" # raise NotImplementedError self [ ColName . BP ] = pd . to_numeric ( self [ ColName . BP ], errors = \"coerce\" ) self = self [ self [ ColName . BP ] . notnull ()] self [ ColName . BP ] = self [ ColName . BP ] . astype ( int ) return self check_chr () \u00b6 Check if chromosome is a valid integer. Source code in easyfinemap/sumstat.py 52 53 54 55 56 57 58 59 60 61 62 63 64 def check_chr ( self ): \"\"\"Check if chromosome is a valid integer.\"\"\" # remove chr from chromosome column, if exists self = self [ self [ ColName . CHR ] . notnull ()] . copy () self [ ColName . CHR ] = self [ ColName . CHR ] . astype ( \"str\" ) . str . replace ( \"chr\" , \"\" ) # replace X, with 23 self [ ColName . CHR ] = self [ ColName . CHR ] . replace ( \"X\" , 23 ) # turn chromosome column into integer self [ ColName . CHR ] = pd . to_numeric ( self [ ColName . CHR ], errors = \"coerce\" ) self = self [ self [ ColName . CHR ] . notnull ()] self [ ColName . CHR ] = self [ ColName . CHR ] . astype ( int ) self = self [ self [ ColName . CHR ] . isin ( CHROMS )] return self check_ea_nea () \u00b6 Check if ea and nea are valid. Source code in easyfinemap/sumstat.py 74 75 76 77 78 79 80 def check_ea_nea ( self ): \"\"\"Check if ea and nea are valid.\"\"\" self [ ColName . EA ] = self [ ColName . EA ] . str . upper () self [ ColName . NEA ] = self [ ColName . NEA ] . str . upper () # remove rows with missing ea or nea self = self [ self [ ColName . EA ] . notnull () & self [ ColName . NEA ] . notnull ()] return self check_eaf () \u00b6 Check if eaf is valid. Source code in easyfinemap/sumstat.py 119 120 121 122 123 124 125 126 127 128 def check_eaf ( self ): \"\"\"Check if eaf is valid.\"\"\" if ColName . EAF in self . columns : self [ ColName . EAF ] = pd . to_numeric ( self [ ColName . EAF ], errors = \"coerce\" ) self = self [ self [ ColName . EAF ] . notnull ()] self [ ColName . EAF ] = self [ ColName . EAF ] . astype ( float ) self = self [( self [ ColName . EAF ] > 0 ) & ( self [ ColName . EAF ] < 1 )] else : pass return self check_maf () \u00b6 Check if maf is valid. Source code in easyfinemap/sumstat.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def check_maf ( self ): \"\"\"Check if maf is valid.\"\"\" if ColName . EAF in self . columns : self [ ColName . MAF ] = self [ ColName . EAF ] else : pass if ColName . MAF in self . columns : self [ ColName . MAF ] = pd . to_numeric ( self [ ColName . MAF ], errors = \"coerce\" ) # self.dropna(subset=[ColName.MAF], inplace=True) self = self [ self [ ColName . MAF ] . notnull ()] self [ ColName . MAF ] = self [ ColName . MAF ] . astype ( float ) self [ ColName . MAF ] = self [ ColName . MAF ] . apply ( lambda x : min ( x , 1 - x )) else : pass return self check_p () \u00b6 Check if p is valid. Source code in easyfinemap/sumstat.py 82 83 84 85 86 87 88 def check_p ( self ): \"\"\"Check if p is valid.\"\"\" self [ ColName . P ] = pd . to_numeric ( self [ ColName . P ], errors = \"coerce\" ) self = self [ self [ ColName . P ] . notnull ()] self [ ColName . P ] = self [ ColName . P ] . astype ( float ) self = self [( self [ ColName . P ] > 0 ) & ( self [ ColName . P ] < 1 )] return self check_se () \u00b6 Check if se is valid. Source code in easyfinemap/sumstat.py 97 98 99 100 101 102 103 def check_se ( self ): \"\"\"Check if se is valid.\"\"\" self [ ColName . SE ] = pd . to_numeric ( self [ ColName . SE ], errors = \"coerce\" ) self = self [ self [ ColName . SE ] . notnull ()] self [ ColName . SE ] = self [ ColName . SE ] . astype ( float ) self = self [ self [ ColName . SE ] > 0 ] return self check_snpid () \u00b6 Check if snpid is valid. Source code in easyfinemap/sumstat.py 105 106 107 108 109 110 111 112 113 114 115 116 117 def check_snpid ( self ): \"\"\"Check if snpid is valid.\"\"\" if ColName . SNPID in self . columns : self . logger . warning ( \"rewriting SNPID column\" ) del self [ ColName . SNPID ] result = self . copy () allele_df = make_SNPID_unique ( result , remove_duplicates = False ) result . insert ( loc = 0 , column = ColName . SNPID , value = allele_df [ ColName . SNPID ] . values ) # type: ignore result . sort_values ( ColName . P , inplace = True ) result . drop_duplicates ( subset = [ ColName . SNPID ], keep = \"first\" , inplace = True ) result . sort_values ([ ColName . CHR , ColName . BP ], inplace = True ) result . reset_index ( drop = True , inplace = True ) return result drop_allna_cols () \u00b6 Drop all columns with all missing values. Source code in easyfinemap/sumstat.py 30 31 32 33 34 35 def drop_allna_cols ( self ): \"\"\"Drop all columns with all missing values.\"\"\" for col in self . columns : if self [ col ] . isnull () . all (): del self [ col ] return self standarize () \u00b6 Standarize the data. Source code in easyfinemap/sumstat.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def standarize ( self ): \"\"\"Standarize the data.\"\"\" self . _validate () self = self . drop_allna_cols () self = self . check_chr () self = self . check_bp () self = self . check_ea_nea () self = self . check_p () self = self . check_beta () self = self . check_se () self = self . check_snpid () self = self . check_eaf () self = self . check_maf () self [ ColName . Z ] = self [ ColName . BETA ] / self [ ColName . SE ] self . reset_index ( drop = True , inplace = True ) return self tools \u00b6 Tools for LD matrix and fine-mapping. Tools ( log_level = 'WARNING' ) \u00b6 check if tools are installed and return their path. Source code in easyfinemap/tools.py 12 13 14 15 def __init__ ( self , log_level : str = \"WARNING\" ): \"\"\"Initialize.\"\"\" self . logger = logger self . logger . setLevel ( log_level ) bcftools property \u00b6 Check if bcftools is installed. plink property \u00b6 Check if plink is installed. utils \u00b6 Utils for easyfinemap. get_significant_snps ( df , pvalue_threshold = 5e-08 ) \u00b6 Get the significant snps from the input file, filter by pvalue. Parameters: Name Type Description Default df pd . DataFrame The input summary statistics. required pvalue_threshold float , optional The pvalue threshold, by default 5e-8 5e-08 Returns: Type Description pd . DataFrame The significant snps, sorted by pvalue. Source code in easyfinemap/utils.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def get_significant_snps ( df : pd . DataFrame , pvalue_threshold : float = 5e-8 ): \"\"\" Get the significant snps from the input file, filter by pvalue. Parameters ---------- df : pd.DataFrame The input summary statistics. pvalue_threshold : float, optional The pvalue threshold, by default 5e-8 Returns ------- pd.DataFrame The significant snps, sorted by pvalue. \"\"\" sig_df = df . loc [ df [ ColName . P ] < pvalue_threshold ] . copy () sig_df . sort_values ( ColName . P , inplace = True ) sig_df . reset_index ( drop = True , inplace = True ) return sig_df make_SNPID_unique ( sumstat , replace_rsIDcol = False , remove_duplicates = True ) \u00b6 Make the SNPID unique. The unique SNPID is chr-bp-sorted(EA,NEA) Parameters: Name Type Description Default sumstat pd . DataFrame The input summary statistics. required replace_rsIDcol bool , optional Whether to replace the rsID column with the unique SNPID, by default False False remove_duplicates bool , optional Whether to remove the duplicated SNPs, keep the one with smallest P-value, by default True True Returns: Type Description pd . DataFrame The summary statistics with unique SNPID. Source code in easyfinemap/utils.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def make_SNPID_unique ( sumstat : pd . DataFrame , replace_rsIDcol : bool = False , remove_duplicates : bool = True ): \"\"\" Make the SNPID unique. The unique SNPID is chr-bp-sorted(EA,NEA) Parameters ---------- sumstat : pd.DataFrame The input summary statistics. replace_rsIDcol : bool, optional Whether to replace the rsID column with the unique SNPID, by default False remove_duplicates : bool, optional Whether to remove the duplicated SNPs, keep the one with smallest P-value, by default True Returns ------- pd.DataFrame The summary statistics with unique SNPID. \"\"\" df = sumstat . copy () allele_df = df [[ ColName . EA , ColName . NEA ]] . copy () b = allele_df . values b . sort ( axis = 1 ) allele_df [[ ColName . EA , ColName . NEA ]] = b allele_df [ ColName . SNPID ] = ( df [ ColName . CHR ] . astype ( str ) + \"-\" + df [ ColName . BP ] . astype ( str ) + \"-\" + allele_df [ ColName . EA ] + \"-\" + allele_df [ ColName . NEA ] ) if replace_rsIDcol : df [ ColName . RSID ] = allele_df [ ColName . SNPID ] else : df . insert ( loc = 0 , column = ColName . SNPID , value = allele_df [ ColName . SNPID ] . values ) # type: ignore if remove_duplicates : df . sort_values ( ColName . P , inplace = True ) if replace_rsIDcol : df . drop_duplicates ( subset = [ ColName . RSID ], keep = \"first\" , inplace = True ) else : df . drop_duplicates ( subset = [ ColName . SNPID ], keep = \"first\" , inplace = True ) df . sort_values ([ ColName . CHR , ColName . BP ], inplace = True ) df . reset_index ( drop = True , inplace = True ) return df","title":"Modules"},{"location":"api/#easyfinemap.cli","text":"Console script for easy_finemap.","title":"cli"},{"location":"api/#easyfinemap.cli.validate_ldref","text":"Validate the LD reference file. Source code in easyfinemap/cli.py 19 20 21 22 23 24 25 26 27 28 29 @app . command () def validate_ldref ( ldref_path : str = typer . Argument ( ... , help = \"The path to the LD reference file.\" ), outprefix : str = typer . Argument ( ... , help = \"The output prefix.\" ), file_type : str = typer . Option ( \"plink\" , \"--file-type\" , \"-f\" , help = \"The file type of the LD reference file.\" ), mac : int = typer . Option ( 10 , \"--mac\" , \"-m\" , help = \"The minor allele count threshold.\" ), threads : int = typer . Option ( 1 , \"--threads\" , \"-t\" , help = \"The number of threads.\" ), ) -> None : \"\"\"Validate the LD reference file.\"\"\" ld = LDRef () ld . valid ( ldref_path , outprefix , file_type , mac , threads )","title":"validate_ldref()"},{"location":"api/#easyfinemap.cli.validate_sumstats","text":"Validate the GWAS summary statistics file. Source code in easyfinemap/cli.py 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 @app . command () def validate_sumstats ( sumstats_path : Path = typer . Argument ( ... , help = \"The path to the GWAS summary statistics file.\" ), output : Path = typer . Argument ( ... , help = \"The output prefix.\" ), ) -> None : \"\"\"Validate the GWAS summary statistics file.\"\"\" if sumstats_path . exists (): sumstats = pd . read_csv ( sumstats_path , sep = \" \\t \" ) typer . echo ( f \"Loaded { sumstats_path } successfully.\" ) typer . echo ( f \"Number of SNPs: { sumstats . shape [ 0 ] } \" ) typer . echo ( f \"Number of columns: { sumstats . shape [ 1 ] } \" ) typer . echo ( f \"Columns: { list ( sumstats . columns ) } \" ) valid_sumstats = SumStat ( sumstats ) valid_sumstats = valid_sumstats . standarize () if output . suffix == \".gz\" : valid_sumstats . to_csv ( output , sep = \" \\t \" , index = False , compression = \"gzip\" ) else : valid_sumstats . to_csv ( output , sep = \" \\t \" , index = False ) typer . echo ( f \"Saved the validated summary statistics to { output } .\" ) else : typer . echo ( f \"Could not find { sumstats_path } .\" ) raise FileNotFoundError ( f \"Could not find { sumstats_path } .\" )","title":"validate_sumstats()"},{"location":"api/#easyfinemap.constant","text":"Define constants used in the package.","title":"constant"},{"location":"api/#easyfinemap.constant.ColName","text":"Define column names.","title":"ColName"},{"location":"api/#easyfinemap.easyfinemap","text":"Main module.","title":"easyfinemap"},{"location":"api/#easyfinemap.easyfinemap.EasyFinemap","text":"Bases: object Main class. Source code in easyfinemap/easyfinemap.py 9 10 11 def __init__ ( self ): \"\"\"Initialize.\"\"\" self . logger = logging . getLogger ( __name__ )","title":"EasyFinemap"},{"location":"api/#easyfinemap.easyfinemap.EasyFinemap.run","text":"Run the program. Source code in easyfinemap/easyfinemap.py 13 14 15 def run ( self ): \"\"\"Run the program.\"\"\" self . logger . info ( \"Running the program\" )","title":"run()"},{"location":"api/#easyfinemap.ldref","text":"Prepare LD reference for easyfinemap. validate the LD reference. 1.1. remove duplicate SNPs. 1.2. make SNP names unique, chr-bp-sorted(EA,NEA). TODO: 1. intersect the significant snps with the LD reference. TODO: 2. make a plink file from the intersected snps. TODO: 3. calculate LD matrix from the plink file.","title":"ldref"},{"location":"api/#easyfinemap.ldref.LDRef","text":"Prepare LD reference for easyfinemap. Parameters: Name Type Description Default ldref_path str The path to the LD reference file. required file_type str , optional The file type of the LD reference file, by default \"plink\" TODO: support other file types, e.g. vcf. required log_level str , optional The log level, by default \"DEBUG\" 'DEBUG' Source code in easyfinemap/ldref.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 def __init__ ( self , log_level : str = \"DEBUG\" ): \"\"\" Initialize the LDRef class. Parameters ---------- ldref_path : str The path to the LD reference file. file_type : str, optional The file type of the LD reference file, by default \"plink\" TODO: support other file types, e.g. vcf. log_level : str, optional The log level, by default \"DEBUG\" \"\"\" self . logger = logging . getLogger ( \"LDRef\" ) self . logger . setLevel ( log_level ) self . plink = Tools () . plink self . tmp_root = Path . cwd () / \"tmp\" / \"ldref\" if not self . tmp_root . exists (): self . tmp_root . mkdir ( parents = True ) self . temp_dir = tempfile . mkdtemp ( dir = self . tmp_root ) self . logger . debug ( f \"LDRef temp dir: { self . temp_dir } \" ) self . temp_dir_path = Path ( self . temp_dir )","title":"LDRef"},{"location":"api/#easyfinemap.ldref.LDRef.clean","text":"Clean the extracted LD reference. Remove duplicated snps. Make SNP names unique, chr-bp-sorted(EA,NEA). Parameters: Name Type Description Default prefix str The prefix of the extracted LD reference. required outprefix str , optional The prefix of the cleaned LD reference, by default None If None, the cleaned LD reference will be saved to the same directory as the extracted LD reference. None mac int , optional The minor allele count threshold, by default 10 SNPs with MAC < mac will be removed. 10 Returns: Type Description None Source code in easyfinemap/ldref.py 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 def clean ( self , inprefix : str , outprefix : Optional [ str ] = None , mac : int = 10 ) -> None : \"\"\" Clean the extracted LD reference. 1. Remove duplicated snps. 2. Make SNP names unique, chr-bp-sorted(EA,NEA). Parameters ---------- prefix : str The prefix of the extracted LD reference. outprefix : str, optional The prefix of the cleaned LD reference, by default None If None, the cleaned LD reference will be saved to the same directory as the extracted LD reference. mac : int, optional The minor allele count threshold, by default 10 SNPs with MAC < mac will be removed. Returns ------- None \"\"\" prefix = f \" { self . temp_dir_path } / { inprefix . split ( '/' )[ - 1 ] } \" bim_file = f \" { inprefix } .bim\" bim = pd . read_csv ( bim_file , sep = \" \\t \" , names = [ ColName . CHR , ColName . RSID , \"cM\" , ColName . BP , ColName . EA , ColName . NEA ] ) bim [ ColName . RSID ] = bim . index # use number as rsid, make sure it is unique bim . to_csv ( f \" { prefix } .bim\" , sep = \" \\t \" , index = False , header = False ) if mac <= 0 : raise ValueError ( f \"mac should be > 0, got { mac } .\" ) cmd = [ self . plink , \"--bed\" , f \" { inprefix } .bed\" , \"--fam\" , f \" { inprefix } .fam\" , \"--bim\" , f \" { prefix } .bim\" , \"--keep-allele-order\" , \"--list-duplicate-vars\" , \"ids-only\" , \"suppress-first\" , \"--out\" , f \" { prefix } \" , ] res = run ( cmd , stdout = PIPE , stderr = PIPE , universal_newlines = True ) self . logger . debug ( ' ' . join ( cmd )) cmd = [ self . plink , \"--bed\" , f \" { inprefix } .bed\" , \"--fam\" , f \" { inprefix } .fam\" , \"--bim\" , f \" { prefix } .bim\" , \"--exclude\" , f \" { prefix } .dupvar\" , \"--mac\" , str ( mac ), \"--keep-allele-order\" , \"--make-bed\" , \"--out\" , f \" { prefix } .clean\" , ] self . logger . debug ( ' ' . join ( cmd )) res = run ( cmd , stdout = PIPE , stderr = PIPE , universal_newlines = True ) if res . returncode != 0 : self . logger . error ( res . stderr ) raise RuntimeError ( res . stderr ) rmdup_bim = pd . read_csv ( f \" { prefix } .clean.bim\" , delim_whitespace = True , names = [ ColName . CHR , ColName . RSID , \"cM\" , ColName . BP , ColName . EA , ColName . NEA ], ) rmdup_bim = make_SNPID_unique ( rmdup_bim , replace_rsIDcol = True , remove_duplicates = False ) rmdup_bim . to_csv ( f \" { prefix } .clean.bim\" , sep = \" \\t \" , index = False , header = False ) if outprefix is not None : shutil . move ( f \" { prefix } .clean.bed\" , f \" { outprefix } .bed\" ) shutil . move ( f \" { prefix } .clean.bim\" , f \" { outprefix } .bim\" ) shutil . move ( f \" { prefix } .clean.fam\" , f \" { outprefix } .fam\" )","title":"clean()"},{"location":"api/#easyfinemap.ldref.LDRef.extract","text":"Extract the genotypes of given region from the LD reference. Parameters: Name Type Description Default inprefix str The input prefix. required outprefix str The output prefix. required chrom int The chromosome number. required start int , optional The start position, by default None None end int , optional The end position, by default None None mac int The minor allele count threshold, by default 10 10 Returns: Type Description None Source code in easyfinemap/ldref.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 def extract ( self , inprefix : str , outprefix : str , chrom : int , start : Optional [ int ] = None , end : Optional [ int ] = None , mac : int = 10 , ) -> None : \"\"\" Extract the genotypes of given region from the LD reference. Parameters ---------- inprefix : str The input prefix. outprefix : str The output prefix. chrom : int The chromosome number. start : int, optional The start position, by default None end : int, optional The end position, by default None mac: int, optional The minor allele count threshold, by default 10 Returns ------- None \"\"\" region_file = f \" { self . temp_dir } / { outprefix . split ( '/' )[ - 1 ] } .region\" if start is None : extract_cmd = [ \"--chr\" , str ( chrom )] else : with open ( region_file , \"w\" ) as f : f . write ( f \" { chrom } \\t { start } \\t { end } \\t region\" ) extract_cmd = [ \"--extract\" , \"range\" , region_file ] if \" {chrom} \" in inprefix : inprefix = inprefix . replace ( \" {chrom} \" , str ( chrom )) if not os . path . exists ( f \" { inprefix } .bed\" ): raise FileNotFoundError ( f \" { inprefix } .bed not found.\" ) cmd = [ self . plink , \"--bfile\" , inprefix , * extract_cmd , \"--keep-allele-order\" , \"--mac\" , str ( mac ), \"--make-bed\" , \"--out\" , outprefix , ] res = run ( cmd , stdout = PIPE , stderr = PIPE , universal_newlines = True ) self . logger . debug ( ' ' . join ( cmd )) self . logger . debug ( f \"extract chr { chrom } : { start } - { end } from { inprefix } \" ) if res . returncode != 0 : self . logger . error ( res . stderr ) self . logger . error ( f 'see log file: { outprefix } .log for details' ) raise RuntimeError ( res . stderr )","title":"extract()"},{"location":"api/#easyfinemap.ldref.LDRef.intersect","text":"Intersect the significant snps with the LD reference. Parameters: Name Type Description Default sig_snps pd . DataFrame The significant snps. required use_ref_EAF bool , optional Use the EAF in the LD reference, by default False False Returns: Type Description pd . DataFrame The intersected significant snps. Source code in easyfinemap/ldref.py 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 def intersect ( self , sig_snps : pd . DataFrame , use_ref_EAF : bool = False ) -> pd . DataFrame : \"\"\" Intersect the significant snps with the LD reference. Parameters ---------- sig_snps : pd.DataFrame The significant snps. use_ref_EAF : bool, optional Use the EAF in the LD reference, by default False Returns ------- pd.DataFrame The intersected significant snps. \"\"\" raise NotImplementedError","title":"intersect()"},{"location":"api/#easyfinemap.ldref.LDRef.valid","text":"Validate the LD reference file. TODO:1. format vcfs to plink files. 2. remove duplicated snps. 3. remove snps with MAC < mac. 4. make SNP names unique, chr-bp-sorted(EA,NEA). TODO:5. mark bim file with \"#easyfinemap validated\" flag in the first line. Parameters: Name Type Description Default ldref_path str The path to the LD reference file. required outprefix str The output prefix. required file_type str , optional The file type of the LD reference file, by default \"plink\" 'plink' mac int The minor allele count threshold, by default 10 10 Raises: Type Description ValueError If the file type is not supported. Returns: Type Description None Source code in easyfinemap/ldref.py 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def valid ( self , ldref_path : str , outprefix : str , file_type : str = \"plink\" , mac : int = 10 , threads : int = 1 ) -> None : \"\"\" Validate the LD reference file. TODO:1. format vcfs to plink files. 2. remove duplicated snps. 3. remove snps with MAC < mac. 4. make SNP names unique, chr-bp-sorted(EA,NEA). TODO:5. mark bim file with \"#easyfinemap validated\" flag in the first line. Parameters ---------- ldref_path : str The path to the LD reference file. outprefix : str The output prefix. file_type : str, optional The file type of the LD reference file, by default \"plink\" mac: int, optional The minor allele count threshold, by default 10 Raises ------ ValueError If the file type is not supported. Returns ------- None \"\"\" if file_type == \"plink\" : self . file_type = file_type else : raise ValueError ( f \"Unsupported file type: { file_type } \" ) params : List [ List [ Union [ str , int ]]] = [[] for _ in range ( 3 )] for chrom in CHROMS : if \" {chrom} \" in ldref_path : inprefix = ldref_path . replace ( \" {chrom} \" , str ( chrom )) if not os . path . exists ( f \" { inprefix } .bed\" ): raise FileNotFoundError ( f \" { inprefix } .bed not found.\" ) else : params [ 0 ] . append ( inprefix ) params [ 1 ] . append ( f \" { outprefix } .chr { chrom } \" ) params [ 2 ] . append ( mac ) else : inprefix = ldref_path if not os . path . exists ( f \" { inprefix } .bed\" ): raise FileNotFoundError ( f \" { inprefix } .bed not found.\" ) else : intermed_prefix = f \" { self . temp_dir } / { outprefix . split ( '/' )[ - 1 ] } .chr { chrom } \" self . extract ( inprefix , intermed_prefix , chrom , mac = mac ) params [ 0 ] . append ( intermed_prefix ) params [ 1 ] . append ( f \" { outprefix } .chr { chrom } \" ) params [ 2 ] . append ( mac ) with Pool ( threads ) as p : p . map ( self . clean , * params )","title":"valid()"},{"location":"api/#easyfinemap.loci","text":"Get the independent loci from the input file. support three approaches: 1. identify the independent lead snps by distance only, TODO:2. identify the independent lead snps by LD clumping, TODO:3. identify the independent lead snps by conditional analysis. than expand the independent lead snps to independent loci by given range. merge the overlapped independent loci (optional).","title":"loci"},{"location":"api/#easyfinemap.loci.indep_snps_by_conditional","text":"Identify the independent snps by conditional analysis. Source code in easyfinemap/loci.py 93 94 95 def indep_snps_by_conditional ( sig_df : pd . DataFrame , ld_df : pd . DataFrame , r2_threshold : float = 0.8 ) -> pd . DataFrame : \"\"\"Identify the independent snps by conditional analysis.\"\"\" raise NotImplementedError","title":"indep_snps_by_conditional()"},{"location":"api/#easyfinemap.loci.indep_snps_by_distance","text":"Identify the independent snps by distance only. Parameters: Name Type Description Default sig_df pd . DataFrame The significant snps. required distance int , optional The distance threshold, by default 1000000 500000 Returns: Type Description pd . DataFrame The independent snps. Source code in easyfinemap/loci.py 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 def indep_snps_by_distance ( sig_df : pd . DataFrame , distance : int = 500000 ) -> pd . DataFrame : \"\"\" Identify the independent snps by distance only. Parameters ---------- sig_df : pd.DataFrame The significant snps. distance : int, optional The distance threshold, by default 1000000 Returns ------- pd.DataFrame The independent snps. \"\"\" sig_df . sort_values ( ColName . P , inplace = True ) lead_snp = [] while len ( sig_df ): lead_snp . append ( sig_df . iloc [[ 0 ]]) sig_df = sig_df [ ~ ( ( sig_df [ ColName . CHR ] == sig_df . iloc [ 0 ][ ColName . CHR ]) & ( sig_df [ ColName . BP ] >= sig_df . iloc [ 0 ][ ColName . BP ] - distance ) & ( sig_df [ ColName . BP ] <= sig_df . iloc [ 0 ][ ColName . BP ] + distance ) ) ] # type: ignore lead_snp = pd . concat ( lead_snp , axis = 0 , ignore_index = True ) return lead_snp","title":"indep_snps_by_distance()"},{"location":"api/#easyfinemap.loci.indep_snps_by_ldclumping","text":"Identify the independent snps by LD clumping. Source code in easyfinemap/loci.py 88 89 90 def indep_snps_by_ldclumping ( sig_df : pd . DataFrame , ld_df : pd . DataFrame , r2_threshold : float = 0.8 ) -> pd . DataFrame : \"\"\"Identify the independent snps by LD clumping.\"\"\" raise NotImplementedError","title":"indep_snps_by_ldclumping()"},{"location":"api/#easyfinemap.loci.leadsnp2loci","text":"Expand the independent lead snps to independent loci by given range. Parameters: Name Type Description Default sig_df pd . DataFrame The independent lead snps. required range int , optional The range, by default 1000000 500000 if_merge bool , optional Whether merge the overlapped loci, by default True True Returns: Type Description pd . DataFrame The independent loci. Source code in easyfinemap/loci.py 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 def leadsnp2loci ( sig_df : pd . DataFrame , range : int = 500000 , if_merge : bool = True ) -> pd . DataFrame : \"\"\" Expand the independent lead snps to independent loci by given range. Parameters ---------- sig_df : pd.DataFrame The independent lead snps. range : int, optional The range, by default 1000000 if_merge : bool, optional Whether merge the overlapped loci, by default True Returns ------- pd.DataFrame The independent loci. \"\"\" loci_df = sig_df . copy () loci_df = make_SNPID_unique ( loci_df ) loci_df = loci_df [[ ColName . CHR , ColName . BP , ColName . P , ColName . SNPID ]] loci_df . columns = [ ColName . CHR , ColName . LEAD_SNP_BP , ColName . LEAD_SNP_P , ColName . LEAD_SNP ] # type: ignore loci_df [ ColName . START ] = loci_df [ ColName . LEAD_SNP_BP ] - range loci_df [ ColName . START ] = loci_df [ ColName . START ] . apply ( lambda x : 0 if x < 0 else x ) loci_df [ ColName . END ] = loci_df [ ColName . LEAD_SNP_BP ] + range loci_df = loci_df [ ColName . loci_cols ] . copy () if if_merge : loci_df = merge_overlapped_loci ( loci_df ) return loci_df","title":"leadsnp2loci()"},{"location":"api/#easyfinemap.loci.merge_overlapped_loci","text":"Merge the overlapped loci. More details: https://stackoverflow.com/questions/57882621/efficient-merge-overlapping-intervals-in-same-pandas- dataframe-with-start-and-fi Parameters: Name Type Description Default loci_df pd . DataFrame The independent loci. required Returns: Type Description pd . DataFrame The merged independent loci. Source code in easyfinemap/loci.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def merge_overlapped_loci ( loci_df : pd . DataFrame ): \"\"\" Merge the overlapped loci. More details: https://stackoverflow.com/questions/57882621/efficient-merge-overlapping-intervals-in-same-pandas-\\ dataframe-with-start-and-fi Parameters ---------- loci_df : pd.DataFrame The independent loci. Returns ------- pd.DataFrame The merged independent loci. \"\"\" merged_loci = loci_df . copy () merged_loci . sort_values ([ ColName . CHR , ColName . START , ColName . END ], inplace = True ) merged_loci [ 'no_overlap' ] = merged_loci [ ColName . START ] > merged_loci [ ColName . END ] . shift () . cummax () merged_loci [ 'diff_chr' ] = merged_loci [ ColName . CHR ] != merged_loci [ ColName . CHR ] . shift () merged_loci [ \"break\" ] = merged_loci [ \"no_overlap\" ] | merged_loci [ 'diff_chr' ] merged_loci [ 'group' ] = merged_loci [ 'break' ] . cumsum () merged_loci = merged_loci . sort_values ([ 'group' , ColName . LEAD_SNP_P ], ascending = True ) agg_func = {} for col in loci_df . columns : if col == ColName . START : agg_func [ col ] = 'min' elif col == ColName . END : agg_func [ col ] = 'max' else : agg_func [ col ] = 'first' result = merged_loci . groupby ( \"group\" ) . agg ( agg_func ) result . reset_index ( drop = True , inplace = True ) return result","title":"merge_overlapped_loci()"},{"location":"api/#easyfinemap.logger","text":"Define custom logger.","title":"logger"},{"location":"api/#easyfinemap.sumstat","text":"Standarize summary statistics for use with EasyFINEMAP.","title":"sumstat"},{"location":"api/#easyfinemap.sumstat.SumStat","text":"Bases: pd . DataFrame extension of pd.Dataframe for standarize summary statistics. Source code in easyfinemap/sumstat.py 16 17 18 19 20 def __init__ ( self , * args , ** kwargs ): \"\"\"Initialize the SumstatAccessor class.\"\"\" super () . __init__ ( * args , ** kwargs ) self . logger = logging . getLogger ( \"Sumstat\" ) self . logger . setLevel ( \"DEBUG\" )","title":"SumStat"},{"location":"api/#easyfinemap.sumstat.SumStat.check_beta","text":"Check if beta is valid. Source code in easyfinemap/sumstat.py 90 91 92 93 94 95 def check_beta ( self ): \"\"\"Check if beta is valid.\"\"\" self [ ColName . BETA ] = pd . to_numeric ( self [ ColName . BETA ], errors = \"coerce\" ) self = self [ self [ ColName . BETA ] . notnull ()] self [ ColName . BETA ] = self [ ColName . BETA ] . astype ( float ) return self","title":"check_beta()"},{"location":"api/#easyfinemap.sumstat.SumStat.check_bp","text":"Check if bp is a valid integer. Source code in easyfinemap/sumstat.py 66 67 68 69 70 71 72 def check_bp ( self ): \"\"\"Check if bp is a valid integer.\"\"\" # raise NotImplementedError self [ ColName . BP ] = pd . to_numeric ( self [ ColName . BP ], errors = \"coerce\" ) self = self [ self [ ColName . BP ] . notnull ()] self [ ColName . BP ] = self [ ColName . BP ] . astype ( int ) return self","title":"check_bp()"},{"location":"api/#easyfinemap.sumstat.SumStat.check_chr","text":"Check if chromosome is a valid integer. Source code in easyfinemap/sumstat.py 52 53 54 55 56 57 58 59 60 61 62 63 64 def check_chr ( self ): \"\"\"Check if chromosome is a valid integer.\"\"\" # remove chr from chromosome column, if exists self = self [ self [ ColName . CHR ] . notnull ()] . copy () self [ ColName . CHR ] = self [ ColName . CHR ] . astype ( \"str\" ) . str . replace ( \"chr\" , \"\" ) # replace X, with 23 self [ ColName . CHR ] = self [ ColName . CHR ] . replace ( \"X\" , 23 ) # turn chromosome column into integer self [ ColName . CHR ] = pd . to_numeric ( self [ ColName . CHR ], errors = \"coerce\" ) self = self [ self [ ColName . CHR ] . notnull ()] self [ ColName . CHR ] = self [ ColName . CHR ] . astype ( int ) self = self [ self [ ColName . CHR ] . isin ( CHROMS )] return self","title":"check_chr()"},{"location":"api/#easyfinemap.sumstat.SumStat.check_ea_nea","text":"Check if ea and nea are valid. Source code in easyfinemap/sumstat.py 74 75 76 77 78 79 80 def check_ea_nea ( self ): \"\"\"Check if ea and nea are valid.\"\"\" self [ ColName . EA ] = self [ ColName . EA ] . str . upper () self [ ColName . NEA ] = self [ ColName . NEA ] . str . upper () # remove rows with missing ea or nea self = self [ self [ ColName . EA ] . notnull () & self [ ColName . NEA ] . notnull ()] return self","title":"check_ea_nea()"},{"location":"api/#easyfinemap.sumstat.SumStat.check_eaf","text":"Check if eaf is valid. Source code in easyfinemap/sumstat.py 119 120 121 122 123 124 125 126 127 128 def check_eaf ( self ): \"\"\"Check if eaf is valid.\"\"\" if ColName . EAF in self . columns : self [ ColName . EAF ] = pd . to_numeric ( self [ ColName . EAF ], errors = \"coerce\" ) self = self [ self [ ColName . EAF ] . notnull ()] self [ ColName . EAF ] = self [ ColName . EAF ] . astype ( float ) self = self [( self [ ColName . EAF ] > 0 ) & ( self [ ColName . EAF ] < 1 )] else : pass return self","title":"check_eaf()"},{"location":"api/#easyfinemap.sumstat.SumStat.check_maf","text":"Check if maf is valid. Source code in easyfinemap/sumstat.py 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 def check_maf ( self ): \"\"\"Check if maf is valid.\"\"\" if ColName . EAF in self . columns : self [ ColName . MAF ] = self [ ColName . EAF ] else : pass if ColName . MAF in self . columns : self [ ColName . MAF ] = pd . to_numeric ( self [ ColName . MAF ], errors = \"coerce\" ) # self.dropna(subset=[ColName.MAF], inplace=True) self = self [ self [ ColName . MAF ] . notnull ()] self [ ColName . MAF ] = self [ ColName . MAF ] . astype ( float ) self [ ColName . MAF ] = self [ ColName . MAF ] . apply ( lambda x : min ( x , 1 - x )) else : pass return self","title":"check_maf()"},{"location":"api/#easyfinemap.sumstat.SumStat.check_p","text":"Check if p is valid. Source code in easyfinemap/sumstat.py 82 83 84 85 86 87 88 def check_p ( self ): \"\"\"Check if p is valid.\"\"\" self [ ColName . P ] = pd . to_numeric ( self [ ColName . P ], errors = \"coerce\" ) self = self [ self [ ColName . P ] . notnull ()] self [ ColName . P ] = self [ ColName . P ] . astype ( float ) self = self [( self [ ColName . P ] > 0 ) & ( self [ ColName . P ] < 1 )] return self","title":"check_p()"},{"location":"api/#easyfinemap.sumstat.SumStat.check_se","text":"Check if se is valid. Source code in easyfinemap/sumstat.py 97 98 99 100 101 102 103 def check_se ( self ): \"\"\"Check if se is valid.\"\"\" self [ ColName . SE ] = pd . to_numeric ( self [ ColName . SE ], errors = \"coerce\" ) self = self [ self [ ColName . SE ] . notnull ()] self [ ColName . SE ] = self [ ColName . SE ] . astype ( float ) self = self [ self [ ColName . SE ] > 0 ] return self","title":"check_se()"},{"location":"api/#easyfinemap.sumstat.SumStat.check_snpid","text":"Check if snpid is valid. Source code in easyfinemap/sumstat.py 105 106 107 108 109 110 111 112 113 114 115 116 117 def check_snpid ( self ): \"\"\"Check if snpid is valid.\"\"\" if ColName . SNPID in self . columns : self . logger . warning ( \"rewriting SNPID column\" ) del self [ ColName . SNPID ] result = self . copy () allele_df = make_SNPID_unique ( result , remove_duplicates = False ) result . insert ( loc = 0 , column = ColName . SNPID , value = allele_df [ ColName . SNPID ] . values ) # type: ignore result . sort_values ( ColName . P , inplace = True ) result . drop_duplicates ( subset = [ ColName . SNPID ], keep = \"first\" , inplace = True ) result . sort_values ([ ColName . CHR , ColName . BP ], inplace = True ) result . reset_index ( drop = True , inplace = True ) return result","title":"check_snpid()"},{"location":"api/#easyfinemap.sumstat.SumStat.drop_allna_cols","text":"Drop all columns with all missing values. Source code in easyfinemap/sumstat.py 30 31 32 33 34 35 def drop_allna_cols ( self ): \"\"\"Drop all columns with all missing values.\"\"\" for col in self . columns : if self [ col ] . isnull () . all (): del self [ col ] return self","title":"drop_allna_cols()"},{"location":"api/#easyfinemap.sumstat.SumStat.standarize","text":"Standarize the data. Source code in easyfinemap/sumstat.py 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 def standarize ( self ): \"\"\"Standarize the data.\"\"\" self . _validate () self = self . drop_allna_cols () self = self . check_chr () self = self . check_bp () self = self . check_ea_nea () self = self . check_p () self = self . check_beta () self = self . check_se () self = self . check_snpid () self = self . check_eaf () self = self . check_maf () self [ ColName . Z ] = self [ ColName . BETA ] / self [ ColName . SE ] self . reset_index ( drop = True , inplace = True ) return self","title":"standarize()"},{"location":"api/#easyfinemap.tools","text":"Tools for LD matrix and fine-mapping.","title":"tools"},{"location":"api/#easyfinemap.tools.Tools","text":"check if tools are installed and return their path. Source code in easyfinemap/tools.py 12 13 14 15 def __init__ ( self , log_level : str = \"WARNING\" ): \"\"\"Initialize.\"\"\" self . logger = logger self . logger . setLevel ( log_level )","title":"Tools"},{"location":"api/#easyfinemap.tools.Tools.bcftools","text":"Check if bcftools is installed.","title":"bcftools"},{"location":"api/#easyfinemap.tools.Tools.plink","text":"Check if plink is installed.","title":"plink"},{"location":"api/#easyfinemap.utils","text":"Utils for easyfinemap.","title":"utils"},{"location":"api/#easyfinemap.utils.get_significant_snps","text":"Get the significant snps from the input file, filter by pvalue. Parameters: Name Type Description Default df pd . DataFrame The input summary statistics. required pvalue_threshold float , optional The pvalue threshold, by default 5e-8 5e-08 Returns: Type Description pd . DataFrame The significant snps, sorted by pvalue. Source code in easyfinemap/utils.py 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 def get_significant_snps ( df : pd . DataFrame , pvalue_threshold : float = 5e-8 ): \"\"\" Get the significant snps from the input file, filter by pvalue. Parameters ---------- df : pd.DataFrame The input summary statistics. pvalue_threshold : float, optional The pvalue threshold, by default 5e-8 Returns ------- pd.DataFrame The significant snps, sorted by pvalue. \"\"\" sig_df = df . loc [ df [ ColName . P ] < pvalue_threshold ] . copy () sig_df . sort_values ( ColName . P , inplace = True ) sig_df . reset_index ( drop = True , inplace = True ) return sig_df","title":"get_significant_snps()"},{"location":"api/#easyfinemap.utils.make_SNPID_unique","text":"Make the SNPID unique. The unique SNPID is chr-bp-sorted(EA,NEA) Parameters: Name Type Description Default sumstat pd . DataFrame The input summary statistics. required replace_rsIDcol bool , optional Whether to replace the rsID column with the unique SNPID, by default False False remove_duplicates bool , optional Whether to remove the duplicated SNPs, keep the one with smallest P-value, by default True True Returns: Type Description pd . DataFrame The summary statistics with unique SNPID. Source code in easyfinemap/utils.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 def make_SNPID_unique ( sumstat : pd . DataFrame , replace_rsIDcol : bool = False , remove_duplicates : bool = True ): \"\"\" Make the SNPID unique. The unique SNPID is chr-bp-sorted(EA,NEA) Parameters ---------- sumstat : pd.DataFrame The input summary statistics. replace_rsIDcol : bool, optional Whether to replace the rsID column with the unique SNPID, by default False remove_duplicates : bool, optional Whether to remove the duplicated SNPs, keep the one with smallest P-value, by default True Returns ------- pd.DataFrame The summary statistics with unique SNPID. \"\"\" df = sumstat . copy () allele_df = df [[ ColName . EA , ColName . NEA ]] . copy () b = allele_df . values b . sort ( axis = 1 ) allele_df [[ ColName . EA , ColName . NEA ]] = b allele_df [ ColName . SNPID ] = ( df [ ColName . CHR ] . astype ( str ) + \"-\" + df [ ColName . BP ] . astype ( str ) + \"-\" + allele_df [ ColName . EA ] + \"-\" + allele_df [ ColName . NEA ] ) if replace_rsIDcol : df [ ColName . RSID ] = allele_df [ ColName . SNPID ] else : df . insert ( loc = 0 , column = ColName . SNPID , value = allele_df [ ColName . SNPID ] . values ) # type: ignore if remove_duplicates : df . sort_values ( ColName . P , inplace = True ) if replace_rsIDcol : df . drop_duplicates ( subset = [ ColName . RSID ], keep = \"first\" , inplace = True ) else : df . drop_duplicates ( subset = [ ColName . SNPID ], keep = \"first\" , inplace = True ) df . sort_values ([ ColName . CHR , ColName . BP ], inplace = True ) df . reset_index ( drop = True , inplace = True ) return df","title":"make_SNPID_unique()"},{"location":"changelog/","text":"Changelog \u00b6 [0.0.5] - 2022-12-26 \u00b6 Added \u00b6 validate GWAS summary statistics Changed \u00b6 Fixed \u00b6 [0.0.4] - 2022-12-26 \u00b6 Added \u00b6 prepare and validate LD reference panel Changed \u00b6 Fixed \u00b6 [0.0.1] - 2022-12-20 \u00b6 Added \u00b6 merge the overlapped independent loci (optional). Changed \u00b6 Fixed \u00b6 [0.0.2] - 2022-12-22 \u00b6 Added \u00b6 identify the independent lead snps by distance only expand the independent lead snps to independent loci by given range. Changed \u00b6 Fixed \u00b6 [0.0.3] - 2022-12-22 \u00b6 Added \u00b6 extract LD ref plink bfile and clean it. Changed \u00b6 Fixed \u00b6","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#005-2022-12-26","text":"","title":"[0.0.5] - 2022-12-26"},{"location":"changelog/#added","text":"validate GWAS summary statistics","title":"Added"},{"location":"changelog/#changed","text":"","title":"Changed"},{"location":"changelog/#fixed","text":"","title":"Fixed"},{"location":"changelog/#004-2022-12-26","text":"","title":"[0.0.4] - 2022-12-26"},{"location":"changelog/#added_1","text":"prepare and validate LD reference panel","title":"Added"},{"location":"changelog/#changed_1","text":"","title":"Changed"},{"location":"changelog/#fixed_1","text":"","title":"Fixed"},{"location":"changelog/#001-2022-12-20","text":"","title":"[0.0.1] - 2022-12-20"},{"location":"changelog/#added_2","text":"merge the overlapped independent loci (optional).","title":"Added"},{"location":"changelog/#changed_2","text":"","title":"Changed"},{"location":"changelog/#fixed_2","text":"","title":"Fixed"},{"location":"changelog/#002-2022-12-22","text":"","title":"[0.0.2] - 2022-12-22"},{"location":"changelog/#added_3","text":"identify the independent lead snps by distance only expand the independent lead snps to independent loci by given range.","title":"Added"},{"location":"changelog/#changed_3","text":"","title":"Changed"},{"location":"changelog/#fixed_3","text":"","title":"Fixed"},{"location":"changelog/#003-2022-12-22","text":"","title":"[0.0.3] - 2022-12-22"},{"location":"changelog/#added_4","text":"extract LD ref plink bfile and clean it.","title":"Added"},{"location":"changelog/#changed_4","text":"","title":"Changed"},{"location":"changelog/#fixed_4","text":"","title":"Fixed"},{"location":"installation/","text":"Installation \u00b6 Stable release \u00b6 To install easy_finemap, run this command in your terminal: $ pip install easy_finemap This is the preferred method to install easy_finemap, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process. From source \u00b6 The source for easy_finemap can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/Jianhua-Wang/easy_finemap Or download the tarball : $ curl -OJL https://github.com/Jianhua-Wang/easy_finemap/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#stable-release","text":"To install easy_finemap, run this command in your terminal: $ pip install easy_finemap This is the preferred method to install easy_finemap, as it will always install the most recent stable release. If you don't have pip installed, this Python installation guide can guide you through the process.","title":"Stable release"},{"location":"installation/#from-source","text":"The source for easy_finemap can be downloaded from the Github repo . You can either clone the public repository: $ git clone git://github.com/Jianhua-Wang/easy_finemap Or download the tarball : $ curl -OJL https://github.com/Jianhua-Wang/easy_finemap/tarball/master Once you have a copy of the source, you can install it with: $ pip install .","title":"From source"},{"location":"usage/","text":"Usage \u00b6 To use easy_finemap in a project import easy_finemap","title":"Usage"},{"location":"usage/#usage","text":"To use easy_finemap in a project import easy_finemap","title":"Usage"}]}