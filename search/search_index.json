{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Index","text":""},{"location":"#easyfinemap","title":"easyfinemap","text":"<p>user-friendly pipeline for GWAS fine-mapping</p> <ul> <li>Documentation: https://Jianhua-Wang.github.io/easyfinemap</li> <li>GitHub: https://github.com/Jianhua-Wang/easyfinemap</li> <li>PyPI: https://pypi.org/project/easyfinemap/</li> <li>Free software: MIT</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>Prepare LD reference for fine-mapping</li> <li>Standardize input summary statistics</li> <li>Identify independent loci by distance, LD clumping, or conditional analysis</li> <li>Fine-mapping with or without LD reference</li> </ul>"},{"location":"#finemapping-approaches","title":"Finemapping approaches","text":"<ul> <li>LD-free<ul> <li>aBF</li> </ul> </li> <li>LD-based<ul> <li>FINEMAP</li> <li>CAVIARBF</li> <li>PAINTOR</li> </ul> </li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":""},{"location":"changelog/#038-2023-09-25","title":"[0.3.8] - 2023-09-25","text":""},{"location":"changelog/#added","title":"Added","text":""},{"location":"changelog/#changed","title":"Changed","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li>fix dependency</li> </ul>"},{"location":"changelog/#035-2023-06-13","title":"[0.3.5] - 2023-06-13","text":""},{"location":"changelog/#added_1","title":"Added","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>fix smunger independency</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":""},{"location":"changelog/#034-2023-06-12","title":"[0.3.4] - 2023-06-12","text":""},{"location":"changelog/#added_2","title":"Added","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>fix bugs in loci by ldblock</li> </ul>"},{"location":"changelog/#fixed_2","title":"Fixed","text":""},{"location":"changelog/#033-2023-06-12","title":"[0.3.3] - 2023-06-12","text":""},{"location":"changelog/#added_3","title":"Added","text":""},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li>fix bugs in loci by ldblock</li> </ul>"},{"location":"changelog/#fixed_3","title":"Fixed","text":""},{"location":"changelog/#032-2023-05-25","title":"[0.3.2] - 2023-05-25","text":""},{"location":"changelog/#added_4","title":"Added","text":""},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>remove pathos</li> </ul>"},{"location":"changelog/#fixed_4","title":"Fixed","text":""},{"location":"changelog/#031-2023-05-25","title":"[0.3.1] - 2023-05-25","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>locus plot</li> </ul>"},{"location":"changelog/#changed_5","title":"Changed","text":""},{"location":"changelog/#fixed_5","title":"Fixed","text":""},{"location":"changelog/#030-2023-05-24","title":"[0.3.0] - 2023-05-24","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li>annotate R2 for locus plot</li> </ul>"},{"location":"changelog/#changed_6","title":"Changed","text":""},{"location":"changelog/#fixed_6","title":"Fixed","text":""},{"location":"changelog/#029-2023-05-24","title":"[0.2.9] - 2023-05-24","text":""},{"location":"changelog/#added_7","title":"Added","text":""},{"location":"changelog/#changed_7","title":"Changed","text":"<ul> <li>Speed up susie by using fread</li> </ul>"},{"location":"changelog/#fixed_7","title":"Fixed","text":""},{"location":"changelog/#028-2023-05-23","title":"[0.2.8] - 2023-05-23","text":""},{"location":"changelog/#added_8","title":"Added","text":""},{"location":"changelog/#changed_8","title":"Changed","text":"<ul> <li>Speed up conditional analysis by intersect ldref with input sumstat first</li> </ul>"},{"location":"changelog/#fixed_8","title":"Fixed","text":""},{"location":"changelog/#027-2023-05-20","title":"[0.2.7] - 2023-05-20","text":""},{"location":"changelog/#added_9","title":"Added","text":""},{"location":"changelog/#changed_9","title":"Changed","text":"<ul> <li>Use tabix to load sumstats when finemap</li> </ul>"},{"location":"changelog/#fixed_9","title":"Fixed","text":""},{"location":"changelog/#026-2023-05-19","title":"[0.2.6] - 2023-05-19","text":""},{"location":"changelog/#added_10","title":"Added","text":"<ul> <li>Support polyfun for finemap and susie</li> </ul>"},{"location":"changelog/#changed_10","title":"Changed","text":"<ul> <li>Use the most significant SNP as lead SNP when COJO fails</li> </ul>"},{"location":"changelog/#fixed_10","title":"Fixed","text":""},{"location":"changelog/#025-2023-03-30","title":"[0.2.5] - 2023-03-30","text":""},{"location":"changelog/#added_11","title":"Added","text":"<ul> <li>set the most significant SNP as SNP, if there are no SNPs with P-value \u2264 threshold.</li> </ul>"},{"location":"changelog/#changed_11","title":"Changed","text":""},{"location":"changelog/#fixed_11","title":"Fixed","text":""},{"location":"changelog/#024-2023-03-30","title":"[0.2.4] - 2023-03-30","text":""},{"location":"changelog/#added_12","title":"Added","text":"<ul> <li>support susie</li> </ul>"},{"location":"changelog/#changed_12","title":"Changed","text":""},{"location":"changelog/#fixed_12","title":"Fixed","text":""},{"location":"changelog/#023-2023-03-24","title":"[0.2.3] - 2023-03-24","text":""},{"location":"changelog/#added_13","title":"Added","text":"<ul> <li>suppor using LD blocks as loci boudaries.</li> </ul>"},{"location":"changelog/#changed_13","title":"Changed","text":""},{"location":"changelog/#fixed_13","title":"Fixed","text":""},{"location":"changelog/#022-2023-03-22","title":"[0.2.2] - 2023-03-22","text":""},{"location":"changelog/#added_14","title":"Added","text":""},{"location":"changelog/#changed_14","title":"Changed","text":"<ul> <li>deleted format function</li> </ul>"},{"location":"changelog/#fixed_14","title":"Fixed","text":""},{"location":"changelog/#021-2023-01-10","title":"[0.2.1] - 2023-01-10","text":""},{"location":"changelog/#added_15","title":"Added","text":"<ul> <li>Instruction of installation</li> </ul>"},{"location":"changelog/#changed_15","title":"Changed","text":""},{"location":"changelog/#fixed_15","title":"Fixed","text":"<ul> <li>typo in easyfinemap.py line519</li> </ul>"},{"location":"changelog/#020-2023-01-10","title":"[0.2.0] - 2023-01-10","text":""},{"location":"changelog/#added_16","title":"Added","text":"<ul> <li>add CAVIARBF</li> </ul>"},{"location":"changelog/#changed_16","title":"Changed","text":""},{"location":"changelog/#fixed_16","title":"Fixed","text":""},{"location":"changelog/#014-2023-01-10","title":"[0.1.4] - 2023-01-10","text":""},{"location":"changelog/#added_17","title":"Added","text":"<ul> <li>add PAINTOR</li> </ul>"},{"location":"changelog/#changed_17","title":"Changed","text":""},{"location":"changelog/#fixed_17","title":"Fixed","text":""},{"location":"changelog/#013-2023-01-09","title":"[0.1.3] - 2023-01-09","text":""},{"location":"changelog/#added_18","title":"Added","text":"<ul> <li>output credible sets</li> </ul>"},{"location":"changelog/#changed_18","title":"Changed","text":""},{"location":"changelog/#fixed_18","title":"Fixed","text":""},{"location":"changelog/#012-2023-01-07","title":"[0.1.2] - 2023-01-07","text":""},{"location":"changelog/#added_19","title":"Added","text":"<ul> <li>update summary statistics using cojo-cond</li> <li>make ld matrix using plink --r2</li> <li>fine-mapping tools: FINEMAP</li> </ul>"},{"location":"changelog/#changed_19","title":"Changed","text":""},{"location":"changelog/#fixed_19","title":"Fixed","text":""},{"location":"changelog/#011-2023-01-07","title":"[0.1.1] - 2023-01-07","text":""},{"location":"changelog/#added_20","title":"Added","text":"<ul> <li>add temp dir decorator</li> <li>identify lead SNPs by LD clumping</li> <li>identify lead SNPs by conditional analysis</li> </ul>"},{"location":"changelog/#changed_20","title":"Changed","text":""},{"location":"changelog/#fixed_20","title":"Fixed","text":""},{"location":"changelog/#005-2022-12-26","title":"[0.0.5] - 2022-12-26","text":""},{"location":"changelog/#added_21","title":"Added","text":"<ul> <li>validate GWAS summary statistics</li> </ul>"},{"location":"changelog/#changed_21","title":"Changed","text":""},{"location":"changelog/#fixed_21","title":"Fixed","text":""},{"location":"changelog/#004-2022-12-26","title":"[0.0.4] - 2022-12-26","text":""},{"location":"changelog/#added_22","title":"Added","text":"<ul> <li>prepare and validate LD reference panel</li> </ul>"},{"location":"changelog/#changed_22","title":"Changed","text":""},{"location":"changelog/#fixed_22","title":"Fixed","text":""},{"location":"changelog/#001-2022-12-20","title":"[0.0.1] - 2022-12-20","text":""},{"location":"changelog/#added_23","title":"Added","text":"<ul> <li>merge the overlapped independent loci (optional).</li> </ul>"},{"location":"changelog/#changed_23","title":"Changed","text":""},{"location":"changelog/#fixed_23","title":"Fixed","text":""},{"location":"changelog/#002-2022-12-22","title":"[0.0.2] - 2022-12-22","text":""},{"location":"changelog/#added_24","title":"Added","text":"<ul> <li>identify the independent lead snps by distance only</li> <li>expand the independent lead snps to independent loci by given range.</li> </ul>"},{"location":"changelog/#changed_24","title":"Changed","text":""},{"location":"changelog/#fixed_24","title":"Fixed","text":""},{"location":"changelog/#003-2022-12-22","title":"[0.0.3] - 2022-12-22","text":""},{"location":"changelog/#added_25","title":"Added","text":"<ul> <li>extract LD ref plink bfile and clean it.</li> </ul>"},{"location":"changelog/#changed_25","title":"Changed","text":""},{"location":"changelog/#fixed_25","title":"Fixed","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install easy_finemap, run this command in your terminal:</p> <pre><code>$ pip install easyfinemap\n</code></pre> <p>This is the preferred method to install easyfinemap, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>The source for easy_finemap can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>$ git clone git://github.com/Jianhua-Wang/easy_finemap\n</code></pre> <p>Or download the tarball:</p> <pre><code>$ curl -OJL https://github.com/Jianhua-Wang/easy_finemap/tarball/master\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>$ pip install .\n</code></pre>"},{"location":"installation/#install-finemappingn-tools-used-in-easyfinemap","title":"Install finemappingn tools used in EasyFinemap","text":"<p>EasyFinemap uses several famous finemapping tools, such as FINEMAP, CAVIARBF, and PAINTOR.</p> <p>You can make them from the source code by yourself or install them using <code>conda</code>.</p> <p>Or you just create the environment of EasyFinemap using <code>conda</code>.</p>"},{"location":"usage/","title":"Usage","text":"<p>To use easy_finemap in a project</p> <pre><code>import easy_finemap\n</code></pre>"},{"location":"api/LDRef/","title":"LDRef","text":"<p>Prepare LD reference for easyfinemap.</p> Source code in <code>easyfinemap/ldref.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize the LDRef class.\"\"\"\n    self.logger = logging.getLogger(\"LDRef\")\n    self.plink = Tools().plink\n    self.gcta = Tools().gcta\n    self.tmp_root = Path.cwd() / \"tmp\" / \"ldref\"\n    if not self.tmp_root.exists():\n        self.tmp_root.mkdir(parents=True)\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.annotate_r2","title":"<code>annotate_r2(sumstat, ldref, ld_snp, temp_dir=None)</code>","text":"<p>Annotate SNPs with r2 to the lead SNP.</p> <p>Parameters:</p> Name Type Description Default <code>sumstat</code> <code>DataFrame</code> <p>The summary statistics.</p> required <code>ldref</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>ld_snp</code> <code>str</code> <p>The lead SNP.</p> required <code>temp_dir</code> <code>Optional[str]</code> <p>The path to the temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The annotated summary statistics.</p> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir('./tmp/ldref')\ndef annotate_r2(\n    self,\n    sumstat: pd.DataFrame,\n    ldref: str,\n    ld_snp: str,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Annotate SNPs with r2 to the lead SNP.\n\n    Parameters\n    ----------\n    sumstat : pd.DataFrame\n        The summary statistics.\n    ldref : str\n        The path to the LD reference file.\n    ld_snp : str\n        The lead SNP.\n    temp_dir : Optional[str], optional\n        The path to the temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The annotated summary statistics.\n    \"\"\"\n    if len(sumstat[ColName.CHR].unique()) &gt; 1:\n        raise ValueError(\"Only one chromosome is allowed.\")\n    chrom = sumstat[ColName.CHR].iloc[0]\n    if len(sumstat) &gt; 100000:\n        self.logger.warning(\"The sumstats is large, it may take a long time to annotate the r2.\")\n    ld = LDRef()\n    r2_df = sumstat.copy()\n    r2_input = ld.intersect(sumstat, ldref.format(chrom=chrom), f\"{temp_dir}/r2_input_{chrom}\")\n    if ld_snp not in r2_input[ColName.SNPID].tolist():\n        raise ValueError(f\"{ld_snp} not in the LD reference.\")\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        f\"{temp_dir}/r2_input_{chrom}\",\n        \"--r2\",\n        \"--ld-snp\",\n        ld_snp,\n        \"--ld-window-kb\",\n        \"100000\",\n        \"--ld-window\",\n        \"99999999\",\n        \"--ld-window-r2\",\n        \"0\",\n        \"--keep-allele-order\",\n        \"--out\",\n        f\"{temp_dir}/r2_{chrom}\",\n    ]\n    self.logger.debug(f\"annotate r2: {' '.join(cmd)}\")\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        res_r2 = pd.read_csv(f\"{temp_dir}/r2_{chrom}.ld\", delim_whitespace=True)\n        res_r2 = pd.Series(res_r2[\"R2\"].values, index=res_r2[\"SNP_B\"].values)\n        r2_df[\"R2\"] = r2_df[ColName.SNPID].map(res_r2)\n        r2_df.loc[r2_df[ColName.SNPID] == ld_snp, \"R2\"] = 1\n        r2_df['R2'] = r2_df['R2'].fillna(-1)\n        return r2_df\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.cojo_cond","title":"<code>cojo_cond(sumstats, cond_snps, ldref, sample_size, use_ref_EAF=False, temp_dir=None)</code>","text":"<p>Conditional analysis. Update the beta, se, pval of the conditional SNPs.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The summary statistics.</p> required <code>cond_snps</code> <code>DataFrame</code> <p>The conditional SNPs.</p> required <code>ldref</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>sample_size</code> <code>int</code> <p>The sample size.</p> required <code>use_ref_EAF</code> <code>bool</code> <p>Whether to use the EAF in the LD reference file, by default False</p> <code>False</code> <code>temp_dir</code> <code>Optional[str]</code> <p>The path to the temporary directory, by default None</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the EAF is not in the sumstats and use_ref_EAF is False.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The updated summary statistics.</p> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir('./tmp/ldref')\ndef cojo_cond(\n    self,\n    sumstats: pd.DataFrame,\n    cond_snps: pd.DataFrame,\n    ldref: str,\n    sample_size: int,\n    use_ref_EAF: bool = False,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Conditional analysis. Update the beta, se, pval of the conditional SNPs.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The summary statistics.\n    cond_snps : pd.DataFrame\n        The conditional SNPs.\n    ldref : str\n        The path to the LD reference file.\n    sample_size : int\n        The sample size.\n    use_ref_EAF : bool, optional\n        Whether to use the EAF in the LD reference file, by default False\n    temp_dir : Optional[str], optional\n        The path to the temporary directory, by default None\n\n    Raises\n    ------\n    ValueError\n        If the EAF is not in the sumstats and use_ref_EAF is False.\n\n    Returns\n    -------\n    pd.DataFrame\n        The updated summary statistics.\n    \"\"\"\n    if not use_ref_EAF and ColName.EAF not in sumstats.columns:\n        raise ValueError(f\"{ColName.EAF} is not in the sumstats, please set use_ref_EAF to True\")\n    chrom = sumstats[ColName.CHR].iloc[0]\n    ld = LDRef()\n    all_sumstats = pd.concat([sumstats, cond_snps], ignore_index=True)\n    all_sumstats.drop_duplicates(subset=[ColName.SNPID], inplace=True)\n    all_sumstats.sort_values(by=[ColName.CHR, ColName.BP], inplace=True)\n    all_sumstats.reset_index(drop=True, inplace=True)\n    cojo_input = ld.intersect(all_sumstats, ldref, f\"{temp_dir}/cojo_input_{chrom}\", use_ref_EAF)\n    cojo_input[ColName.N] = sample_size\n    cojo_input = cojo_input[\n        [ColName.SNPID, ColName.EA, ColName.NEA, ColName.EAF, ColName.BETA, ColName.SE, ColName.P, ColName.N]\n    ]\n    cojo_input.rename(\n        columns={\n            ColName.SNPID: \"SNP\",\n            ColName.EA: \"A1\",\n            ColName.NEA: \"A2\",\n            ColName.EAF: \"freq\",\n            ColName.BETA: \"b\",\n            ColName.SE: \"se\",\n            ColName.P: \"p\",\n            ColName.N: \"N\",\n        },\n        inplace=True,\n    )\n    cojo_p_file = f\"{temp_dir}/cojo_input_{chrom}.ma\"\n    cojo_input.to_csv(cojo_p_file, sep=\" \", index=False)\n    with open(f\"{temp_dir}/cojo_cond_{chrom}.snps\", \"w\") as f:\n        f.write('\\n'.join(cond_snps[ColName.SNPID].tolist()))\n    cojo_outfile = f\"{temp_dir}/cojo_{chrom}.cond\"\n    cmd = [\n        self.gcta,\n        \"--bfile\",\n        ldref,\n        \"--cojo-file\",\n        cojo_p_file,\n        \"--cojo-cond\",\n        f\"{temp_dir}/cojo_cond_{chrom}.snps\",\n        \"--out\",\n        cojo_outfile,\n    ]\n    self.logger.debug(f\"conditional analysis: {' '.join(cmd)}\")\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        cond_res = pd.read_csv(f\"{cojo_outfile}.cma.cojo\", sep=\"\\t\", usecols=[\"SNP\", \"bC\", \"bC_se\", \"pC\"])\n        cond_res.rename(\n            columns={\"SNP\": ColName.SNPID, \"bC\": ColName.COJO_BETA, \"bC_se\": ColName.COJO_SE, \"pC\": ColName.COJO_P},\n            inplace=True,\n        )\n        output = sumstats.merge(cond_res, on=ColName.SNPID, how=\"left\")\n        output = output.dropna(subset=[ColName.COJO_P, ColName.COJO_BETA, ColName.COJO_SE])\n        return output\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.extract","title":"<code>extract(inprefix, outprefix, chrom, temp_dir=None, start=None, end=None, mac=10)</code>","text":"<p>Extract the genotypes of given region from the LD reference.</p> <p>Parameters:</p> Name Type Description Default <code>inprefix</code> <code>str</code> <p>The input prefix.</p> required <code>outprefix</code> <code>str</code> <p>The output prefix.</p> required <code>chrom</code> <code>int</code> <p>The chromosome number.</p> required <code>temp_dir</code> <code>str</code> <p>The temporary directory.</p> <code>None</code> <code>start</code> <code>int</code> <p>The start position, by default None</p> <code>None</code> <code>end</code> <code>int</code> <p>The end position, by default None</p> <code>None</code> <code>mac</code> <code>int</code> <p>The minor allele count threshold, by default 10</p> <code>10</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir(dir=\"./tmp/ldref\")\ndef extract(\n    self,\n    inprefix: str,\n    outprefix: str,\n    chrom: int,\n    temp_dir: Optional[str] = None,\n    start: Optional[int] = None,\n    end: Optional[int] = None,\n    mac: int = 10,\n) -&gt; None:\n\"\"\"\n    Extract the genotypes of given region from the LD reference.\n\n    Parameters\n    ----------\n    inprefix : str\n        The input prefix.\n    outprefix : str\n        The output prefix.\n    chrom : int\n        The chromosome number.\n    temp_dir : str\n        The temporary directory.\n    start : int, optional\n        The start position, by default None\n    end : int, optional\n        The end position, by default None\n    mac: int, optional\n        The minor allele count threshold, by default 10\n\n    Returns\n    -------\n    None\n    \"\"\"\n    region_file = f\"{temp_dir}/{outprefix.split('/')[-1]}.region\"\n    if start is None:\n        extract_cmd = [\"--chr\", str(chrom)]\n    else:\n        with open(region_file, \"w\") as f:\n            f.write(f\"{chrom}\\t{start}\\t{end}\\tregion\")\n        extract_cmd = [\"--extract\", \"range\", region_file]\n\n    if \"{chrom}\" in inprefix:\n        inprefix = inprefix.replace(\"{chrom}\", str(chrom))\n    if not os.path.exists(f\"{inprefix}.bed\"):\n        raise FileNotFoundError(f\"{inprefix}.bed not found.\")\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        inprefix,\n        *extract_cmd,\n        \"--keep-allele-order\",\n        \"--mac\",\n        str(mac),\n        \"--make-bed\",\n        \"--out\",\n        outprefix,\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    self.logger.debug(' '.join(cmd))\n    self.logger.debug(f\"extract chr{chrom}:{start}-{end} from {inprefix}\")\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        self.logger.error(f'see log file: {outprefix}.log for details')\n        raise RuntimeError(res.stderr)\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.intersect","title":"<code>intersect(sumstats, ldref, out_plink, use_ref_EAF=False, temp_dir=None)</code>","text":"<p>Intersect the significant snps with the LD reference.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The summary statistics.</p> required <code>ldref</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>out_plink</code> <code>str</code> <p>The output prefix.</p> required <code>use_ref_EAF</code> <code>bool</code> <p>Use the EAF in the LD reference, by default False</p> <code>False</code> <code>temp_dir</code> <code>Optional[str]</code> <p>The path to the temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The intersected significant snps.</p> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir(dir=\"./tmp/ldref\")\ndef intersect(\n    self,\n    sumstats: pd.DataFrame,\n    ldref: str,\n    out_plink: str,\n    use_ref_EAF: bool = False,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Intersect the significant snps with the LD reference.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The summary statistics.\n    ldref : str\n        The path to the LD reference file.\n    out_plink : str\n        The output prefix.\n    use_ref_EAF : bool, optional\n        Use the EAF in the LD reference, by default False\n    temp_dir : Optional[str], optional\n        The path to the temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The intersected significant snps.\n    \"\"\"\n    if not os.path.exists(f\"{ldref}.bim\"):\n        raise FileNotFoundError(f\"{ldref}.bim not found.\")\n    sumstats[ColName.SNPID].to_csv(f\"{temp_dir}/overlap_snpid.txt\", index=False, header=False)\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        ldref,\n        \"--extract\",\n        f\"{temp_dir}/overlap_snpid.txt\",\n        \"--keep-allele-order\",\n        \"--make-bed\",\n        \"--out\",\n        out_plink,\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    self.logger.debug(' '.join(cmd))\n    self.logger.debug(f\"intersect {sumstats.shape[0]} SNPs with {ldref}\")\n    if res.returncode != 0:\n        self.logger.warning(res.stderr)\n        self.logger.warning(f'see log file: {out_plink}.log for details')\n        # raise RuntimeError(res.stderr)\n        return pd.DataFrame()\n    else:\n        bim = pd.read_csv(\n            f\"{out_plink}.bim\",\n            delim_whitespace=True,\n            names=[ColName.CHR, ColName.RSID, \"cM\", ColName.BP, ColName.EA, ColName.NEA],\n        )\n        overlap_sumstat = sumstats[sumstats[ColName.SNPID].isin(bim[ColName.RSID])].copy()\n        overlap_sumstat.reset_index(drop=True, inplace=True)\n\n        if use_ref_EAF:\n            cmd = [\n                self.plink,\n                \"--bfile\",\n                out_plink,\n                \"--freq\",\n                \"--out\",\n                f\"{temp_dir}/freq\",\n            ]\n            res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n            self.logger.debug(f\"calculate EAF of {out_plink}\")\n            self.logger.debug(f\"calculate EAF: {' '.join(cmd)}\")\n            # if res.returncode != 0:\n            #     self.logger.error(res.stderr)\n            #     self.logger.error(f'see log file: {temp_dir}/freq.log for details')\n            #     raise RuntimeError(res.stderr)\n            freq = pd.read_csv(f\"{temp_dir}/freq.frq\", delim_whitespace=True)\n            freq['A2_frq'] = 1 - freq['MAF']\n            overlap_sumstat['EAF'] = freq['A2_frq'].where(freq['A2'] == overlap_sumstat['EA'], freq['MAF'])\n            overlap_sumstat['MAF'] = freq['MAF']\n        return overlap_sumstat\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.make_ld","title":"<code>make_ld(ldref, outprefix, **kwargs)</code>","text":"<p>Make the LD matrix.</p> <p>TODO: Calculate LD matrix using plink-pandas, because plink1.9 --ld contains bug.</p> <p>Parameters:</p> Name Type Description Default <code>ldref</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>outprefix</code> <code>str</code> <p>The output prefix.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the return code is not 0.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir('./tmp/ldref')\ndef make_ld(\n    self,\n    ldref: str,\n    outprefix: str,\n    **kwargs,\n):\n\"\"\"\n    Make the LD matrix.\n\n    TODO: Calculate LD matrix using plink-pandas, because plink1.9 --ld contains bug.\n\n    Parameters\n    ----------\n    ldref : str\n        The path to the LD reference file.\n    outprefix : str\n        The output prefix.\n\n    Raises\n    ------\n    RuntimeError\n        If the return code is not 0.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    self.logger.info(\"Making the LD matrix\")\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        ldref,\n        \"--r2\",\n        \"square\",\n        \"spaces\",\n        \"--threads\",\n        \"1\",\n        \"--out\",\n        outprefix,\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    self.logger.debug(f\"get LD matrix: {' '.join(cmd)}\")\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        self.logger.debug(\"LD matrix is made\")\n        run([\"sed\", \"-i\", \"s/nan/1e-6/g\", f\"{outprefix}.ld\"])\n</code></pre>"},{"location":"api/LDRef/#easyfinemap.LDRef.valid","title":"<code>valid(ldref_path, outprefix, file_type='plink', mac=10, threads=1, temp_dir=None)</code>","text":"<p>Validate the LD reference file.</p> <p>TODO:1. format vcfs to plink files. 2. remove duplicated snps. 3. remove snps with MAC &lt; mac. 4. make SNP names unique, chr-bp-sorted(EA,NEA). TODO:5. mark bim file with \"#easyfinemap validated\" flag in the first line.</p> <p>Parameters:</p> Name Type Description Default <code>ldref_path</code> <code>str</code> <p>The path to the LD reference file.</p> required <code>outprefix</code> <code>str</code> <p>The output prefix.</p> required <code>file_type</code> <code>str</code> <p>The file type of the LD reference file, by default \"plink\"</p> <code>'plink'</code> <code>mac</code> <code>int</code> <p>The minor allele count threshold, by default 10 SNPs with MAC &lt; mac will be removed.</p> <code>10</code> <code>threads</code> <code>int</code> <p>The number of threads to use, by default 1</p> <code>1</code> <code>temp_dir</code> <code>Optional[str]</code> <p>The path to the temporary directory, by default None</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the file type is not supported.</p> <p>Returns:</p> Type Description <code>None</code> Source code in <code>easyfinemap/ldref.py</code> <pre><code>@io_in_tempdir(dir='./tmp/ldref')\ndef valid(\n    self,\n    ldref_path: str,\n    outprefix: str,\n    file_type: str = \"plink\",\n    mac: int = 10,\n    threads: int = 1,\n    temp_dir: Optional[str] = None,\n) -&gt; None:\n\"\"\"\n    Validate the LD reference file.\n\n    TODO:1. format vcfs to plink files.\n    2. remove duplicated snps.\n    3. remove snps with MAC &lt; mac.\n    4. make SNP names unique, chr-bp-sorted(EA,NEA).\n    TODO:5. mark bim file with \"#easyfinemap validated\" flag in the first line.\n\n    Parameters\n    ----------\n    ldref_path : str\n        The path to the LD reference file.\n    outprefix : str\n        The output prefix.\n    file_type : str, optional\n        The file type of the LD reference file, by default \"plink\"\n    mac: int, optional\n        The minor allele count threshold, by default 10\n        SNPs with MAC &lt; mac will be removed.\n    threads : int, optional\n        The number of threads to use, by default 1\n    temp_dir : Optional[str], optional\n        The path to the temporary directory, by default None\n\n    Raises\n    ------\n    ValueError\n        If the file type is not supported.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if file_type == \"plink\":\n        self.file_type = file_type\n    else:\n        raise ValueError(f\"Unsupported file type: {file_type}\")\n\n    params: List[List[Union[str, int]]] = [[] for _ in range(3)]\n    for chrom in CHROMS:\n        if \"{chrom}\" in ldref_path:\n            inprefix = ldref_path.replace(\"{chrom}\", str(chrom))\n            if not os.path.exists(f\"{inprefix}.bed\"):\n                if chrom == 23:\n                    inprefix = ldref_path.replace(\"{chrom}\", \"X\")\n                    if os.path.exists(f\"{inprefix}.bed\"):\n                        self.logger.warning(f\"chr{chrom} not found, use X instead.\")\n                        params[0].append(inprefix)\n                        params[1].append(f\"{outprefix}.chr{chrom}\")\n                        params[2].append(mac)\n                    else:\n                        self.logger.warning(f\"{inprefix}.bed not found.\")\n                else:\n                    self.logger.warning(f\"{inprefix}.bed not found.\")\n                    continue\n            else:\n                params[0].append(inprefix)\n                params[1].append(f\"{outprefix}.chr{chrom}\")\n                params[2].append(mac)\n        else:\n            inprefix = ldref_path\n            if not os.path.exists(f\"{inprefix}.bed\"):\n                raise FileNotFoundError(f\"{inprefix}.bed not found.\")\n            else:\n                # check if chrom is in the bim file\n                res = check_output(f'grep \"^{chrom}[[:space:]]\" {inprefix}.bim | head -n 1', shell=True)\n                if len(res.decode()) == 0:\n                    self.logger.warning(f\"Chrom {chrom} not found in {inprefix}.bim\")\n                    continue\n                else:\n                    intermed_prefix = f\"{temp_dir}/{outprefix.split('/')[-1]}.chr{chrom}\"\n                    self.extract(inprefix, intermed_prefix, chrom, mac=mac)\n                    params[0].append(intermed_prefix)\n                    params[1].append(f\"{outprefix}.chr{chrom}\")\n                    params[2].append(mac)\n\n    with Pool(threads) as p:\n        p.map(self._clean_per_chr, *params)\n</code></pre>"},{"location":"api/Loci/","title":"Loci","text":"<p>Identify the independent loci.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize the Loci class.\"\"\"\n    self.logger = logging.getLogger(\"Loci\")\n    self.plink = Tools().plink\n    self.gcta = Tools().gcta\n    self.tmp_root = Path.cwd() / \"tmp\" / \"loci\"\n    if not self.tmp_root.exists():\n        self.tmp_root.mkdir(parents=True)\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.clump_per_chr","title":"<code>clump_per_chr(sig_df, ldref, clump_p1, clump_kb, clump_r2, temp_dir=None)</code>","text":"<p>LD clumping per chromosome.</p> <p>Parameters:</p> Name Type Description Default <code>sig_df</code> <code>DataFrame</code> <p>The significant snps.</p> required <code>ldref</code> <code>str</code> <p>The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.</p> required <code>clump_p1</code> <code>float</code> <p>The p1 threshold.</p> required <code>clump_kb</code> <code>int</code> <p>The kb threshold.</p> required <code>clump_r2</code> <code>float</code> <p>The r2 threshold.</p> required <code>temp_dir</code> <code>Optional[str]</code> <p>The temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The clumped snps.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@io_in_tempdir(dir=\"./tmp/loci\")\ndef clump_per_chr(\n    self,\n    sig_df: pd.DataFrame,\n    ldref: str,\n    clump_p1: float,\n    clump_kb: int,\n    clump_r2: float,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    LD clumping per chromosome.\n\n    Parameters\n    ----------\n    sig_df : pd.DataFrame\n        The significant snps.\n    ldref : str\n        The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.\n    clump_p1 : float\n        The p1 threshold.\n    clump_kb : int\n        The kb threshold.\n    clump_r2 : float\n        The r2 threshold.\n    temp_dir : Optional[str], optional\n        The temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The clumped snps.\n    \"\"\"\n    chrom = sig_df[ColName.CHR].unique()[0]\n    clump_p_file = f\"{temp_dir}/clump_p_{chrom}.txt\"\n    sig_df[[ColName.SNPID, ColName.P]].to_csv(clump_p_file, sep=\"\\t\", index=False)\n    clump_outfile = f\"{temp_dir}/clump_{chrom}.clumped\"\n    cmd = [\n        self.plink,\n        \"--bfile\",\n        ldref.format(chrom=chrom),\n        \"--clump\",\n        clump_p_file,\n        \"--clump-p1\",\n        str(clump_p1),\n        \"--clump-kb\",\n        str(clump_kb),\n        \"--clump-r2\",\n        str(clump_r2),\n        \"--clump-snp-field\",\n        ColName.SNPID,\n        \"--clump-field\",\n        ColName.P,\n        \"--out\",\n        f\"{temp_dir}/clump_{chrom}\",\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        if os.path.exists(clump_outfile):\n            clump_snps = pd.read_csv(clump_outfile, delim_whitespace=True, usecols=[\"SNP\"])\n            clump_snps = clump_snps[\"SNP\"].to_list()\n            clump_snps = sig_df[sig_df[ColName.SNPID].isin(clump_snps)]\n            return clump_snps\n        else:\n            logging.warning(f\"No clumped snps found for chromosome {chrom}\")\n            return pd.DataFrame()\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.cojo_slct","title":"<code>cojo_slct(sumstats, ldref, sample_size, cojo_window_kb=10000, cojo_collinear=0.9, diff_freq=0.2, sig_threshold=5e-08, use_ref_EAF=False, temp_dir=None)</code>","text":"<p>Conditional analysis for input sumstatistics.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The input sumstatistics, from same chromosome or locus.</p> required <code>ldref</code> <code>str</code> <p>The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.</p> required <code>sample_size</code> <code>int</code> <p>The sample size of the input sumstatistics.</p> required <code>cojo_window_kb</code> <code>int</code> <p>The cojo window, by default 10000, unit: kb</p> <code>10000</code> <code>cojo_collinear</code> <code>float</code> <p>The cojo collinear, by default 0.9</p> <code>0.9</code> <code>diff_freq</code> <code>float</code> <p>The difference frequency, by default 0.2</p> <code>0.2</code> <code>sig_threshold</code> <code>float</code> <p>The significance threshold, by default 5e-8</p> <code>5e-08</code> <code>use_ref_EAF</code> <code>bool</code> <p>Whether to use the reference EAF, by default False</p> <code>False</code> <code>temp_dir</code> <code>Optional[str]</code> <p>The temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The conditional snps.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@io_in_tempdir(dir=\"./tmp/loci\")\ndef cojo_slct(\n    self,\n    sumstats: pd.DataFrame,\n    ldref: str,\n    sample_size: int,\n    cojo_window_kb: int = 10000,\n    cojo_collinear: float = 0.9,\n    diff_freq: float = 0.2,\n    sig_threshold: float = 5e-8,\n    use_ref_EAF: bool = False,\n    temp_dir: Optional[str] = None,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Conditional analysis for input sumstatistics.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The input sumstatistics, from same chromosome or locus.\n    ldref : str\n        The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.\n    sample_size : int\n        The sample size of the input sumstatistics.\n    cojo_window_kb : int, optional\n        The cojo window, by default 10000, unit: kb\n    cojo_collinear : float, optional\n        The cojo collinear, by default 0.9\n    diff_freq : float, optional\n        The difference frequency, by default 0.2\n    sig_threshold : float, optional\n        The significance threshold, by default 5e-8\n    use_ref_EAF : bool, optional\n        Whether to use the reference EAF, by default False\n    temp_dir : Optional[str], optional\n        The temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The conditional snps.\n    \"\"\"\n    chrom = sumstats[ColName.CHR].unique()[0]\n    cojo_input = sumstats.copy()\n    ld = LDRef()\n    cojo_input = ld.intersect(sumstats, ldref, f\"{temp_dir}/cojo_input_{chrom}\", use_ref_EAF)\n    if cojo_input.empty:\n        self.logger.warning(f\"No SNPs in LD reference for chromosome {temp_dir}/cojo_input_{chrom}\")\n        self.logger.warning(\"Use the most significant SNP as the independent lead SNP.\")\n        cojo_snps = sumstats.loc[sumstats[ColName.P] == sumstats[ColName.P].min()].copy()\n    else:\n        cojo_input[ColName.N] = sample_size\n        cojo_input = cojo_input[\n            [ColName.SNPID, ColName.EA, ColName.NEA, ColName.EAF, ColName.BETA, ColName.SE, ColName.P, ColName.N]\n        ]\n        cojo_input.rename(\n            columns={\n                ColName.SNPID: \"SNP\",\n                ColName.EA: \"A1\",\n                ColName.NEA: \"A2\",\n                ColName.EAF: \"freq\",\n                ColName.BETA: \"b\",\n                ColName.SE: \"se\",\n                ColName.P: \"p\",\n                ColName.N: \"N\",\n            },\n            inplace=True,\n        )\n        cojo_p_file = f\"{temp_dir}/cojo_input_{chrom}.ma\"\n        cojo_input.to_csv(cojo_p_file, sep=\" \", index=False)\n        cojo_outfile = f\"{temp_dir}/cojo_{chrom}.slct\"\n        cmd = [\n            self.gcta,\n            \"--bfile\",\n            f\"{temp_dir}/cojo_input_{chrom}\",\n            \"--cojo-file\",\n            cojo_p_file,\n            \"--cojo-slct\",\n            \"--cojo-p\",\n            str(sig_threshold),\n            \"--cojo-wind\",\n            str(cojo_window_kb),\n            \"--cojo-collinear\",\n            str(cojo_collinear),\n            \"--diff-freq\",\n            str(diff_freq),\n            \"--out\",\n            cojo_outfile,\n        ]\n        self.logger.debug(f\"Run cojo-slct: {' '.join(cmd)}\")\n        res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n        if res.returncode != 0:\n            self.logger.warning(res.stderr)\n            self.logger.warning(f\"Run cojo-slct failed for chromosome {chrom}\")\n            self.logger.warning(\"Use the most significant SNP as the independent lead SNP.\")\n            cojo_snps = sumstats.loc[sumstats[ColName.P] == sumstats[ColName.P].min()].copy()\n        else:\n            if os.path.exists(f\"{cojo_outfile}.jma.cojo\"):\n                cojo_snps = pd.read_csv(\n                    f\"{cojo_outfile}.jma.cojo\", delim_whitespace=True, usecols=[\"SNP\", \"bJ\", \"bJ_se\", \"pJ\"]\n                )\n                cojo_snps.rename(\n                    columns={\n                        \"SNP\": ColName.SNPID,\n                        \"bJ\": ColName.COJO_BETA,\n                        \"bJ_se\": ColName.COJO_SE,\n                        \"pJ\": ColName.COJO_P,\n                    },\n                    inplace=True,\n                )\n                cojo_snps = cojo_snps[cojo_snps[ColName.COJO_P] &lt;= sig_threshold]\n                cojo_snps = sumstats.merge(cojo_snps, on=ColName.SNPID, how=\"inner\")\n            else:\n                self.logger.warning(f\"No conditional snps found for chromosome {chrom}\")\n                self.logger.warning(\"Use the most significant SNP as the independent lead SNP.\")\n                cojo_snps = sumstats.loc[sumstats[ColName.P] == sumstats[ColName.P].min()].copy()\n    return cojo_snps\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.identify_indep_loci","title":"<code>identify_indep_loci(sumstats, sig_threshold=5e-08, loci_extend=500, ldblock=None, if_merge=False, outprefix=None, ldref=None, method='distance', distance=500, clump_kb=500, clump_r2=0.1, sample_size=None, cojo_window_kb=10000, cojo_collinear=0.9, diff_freq=0.2, only_use_sig_snps=False, use_ref_EAF=False, threads=1)</code>","text":"<p>Identify the independent loci.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The input summary statistics.</p> required <code>sig_threshold</code> <code>float</code> <p>The pvalue threshold, by default 5e-8</p> <code>5e-08</code> <code>loci_extend</code> <code>int</code> <p>The range to extend the independent lead snps to independent loci, by default 500, unit: kb</p> <code>500</code> <code>if_merge</code> <code>bool</code> <p>Whether to merge the overlapped independent loci, by default False</p> <code>False</code> <code>ldref</code> <code>Optional[str]</code> <p>The LD reference file, by default None</p> <code>None</code> <code>method</code> <code>str</code> <p>The method to identify the independent loci, by default \"distance\", choose from [\"distance\", \"clumping\", \"conditional\"]</p> <code>'distance'</code> <code>distance</code> <code>int</code> <p>The distance threshold to identify the independent loci, by default 500, unit: kb</p> <code>500</code> <code>clump_kb</code> <code>int</code> <p>The distance threshold for LD clumping, by default 10000, unit: kb</p> <code>500</code> <code>clump_r2</code> <code>float</code> <p>The r2 threshold for LD clumping, by default 0.1</p> <code>0.1</code> <code>sample_size</code> <code>Optional[int]</code> <p>The sample size for conditional analysis, by default None</p> <code>None</code> <code>cojo_window_kb</code> <code>int</code> <p>The distance threshold for conditional analysis, by default 10000</p> <code>10000</code> <code>cojo_collinear</code> <code>float</code> <p>The collinear threshold for conditional analysis, by default 0.9</p> <code>0.9</code> <code>diff_freq</code> <code>float</code> <p>The difference frequency threshold for conditional analysis, by default 0.2</p> <code>0.2</code> <code>only_use_sig_snps</code> <code>bool</code> <p>Whether to use the significant snps for conditional analysis, by default False</p> <code>False</code> <code>use_ref_EAF</code> <code>bool</code> <p>Whether to use the reference EAF for conditional analysis, by default False</p> <code>False</code> <code>threads</code> <code>int</code> <p>The number of threads, by default 1</p> <code>1</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, DataFrame]</code> <p>The independent lead snps and independent loci.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>def identify_indep_loci(\n    self,\n    sumstats: pd.DataFrame,\n    sig_threshold: float = 5e-8,\n    loci_extend: int = 500,\n    ldblock: Optional[str] = None,\n    if_merge: bool = False,\n    outprefix: Optional[str] = None,\n    ldref: Optional[str] = None,\n    method: str = \"distance\",\n    distance: int = 500,\n    clump_kb: int = 500,\n    clump_r2: float = 0.1,\n    sample_size: Optional[int] = None,\n    cojo_window_kb: int = 10000,\n    cojo_collinear: float = 0.9,\n    diff_freq: float = 0.2,\n    only_use_sig_snps: bool = False,\n    use_ref_EAF: bool = False,\n    threads: int = 1,\n) -&gt; Union[Tuple[pd.DataFrame, pd.DataFrame], None]:\n\"\"\"\n    Identify the independent loci.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The input summary statistics.\n    sig_threshold : float, optional\n        The pvalue threshold, by default 5e-8\n    loci_extend : int, optional\n        The range to extend the independent lead snps to independent loci, by default 500, unit: kb\n    if_merge : bool, optional\n        Whether to merge the overlapped independent loci, by default False\n    ldref : Optional[str], optional\n        The LD reference file, by default None\n    method : str, optional\n        The method to identify the independent loci, by default \"distance\",\n        choose from [\"distance\", \"clumping\", \"conditional\"]\n    distance : int, optional\n        The distance threshold to identify the independent loci, by default 500, unit: kb\n    clump_kb : int, optional\n        The distance threshold for LD clumping, by default 10000, unit: kb\n    clump_r2 : float, optional\n        The r2 threshold for LD clumping, by default 0.1\n    sample_size : Optional[int], optional\n        The sample size for conditional analysis, by default None\n    cojo_window_kb : int, optional\n        The distance threshold for conditional analysis, by default 10000\n    cojo_collinear : float, optional\n        The collinear threshold for conditional analysis, by default 0.9\n    diff_freq : float, optional\n        The difference frequency threshold for conditional analysis, by default 0.2\n    only_use_sig_snps : bool, optional\n        Whether to use the significant snps for conditional analysis, by default False\n    use_ref_EAF : bool, optional\n        Whether to use the reference EAF for conditional analysis, by default False\n    threads : int, optional\n        The number of threads, by default 1\n\n    Returns\n    -------\n    Tuple[pd.DataFrame, pd.DataFrame]\n        The independent lead snps and independent loci.\n    \"\"\"\n    sumstats = make_SNPID_unique(sumstats)\n    if ldblock is not None:\n        ldblock = pd.read_csv(ldblock, sep=\"\\t\", names=[ColName.CHR, ColName.START, ColName.END])\n    if method == \"distance\":\n        sig_df = get_significant_snps(sumstats, sig_threshold)\n        lead_snp = self.indep_snps_by_distance(sig_df, distance, ldblock)\n    elif method == \"clumping\":\n        clump_p1 = sig_threshold\n        if ldref is not None:\n            sig_df = get_significant_snps(sumstats, sig_threshold)\n            lead_snp = self.indep_snps_by_ldclumping(sig_df, ldref, clump_p1, clump_kb, clump_r2)\n        else:\n            raise ValueError(f\"Please provide the ldref file for method: {method}\")\n    elif method == \"conditional\":\n        if ldref is None:\n            raise ValueError(\"Please provide the ldref file for conditional analysis.\")\n        if sample_size is None:\n            raise ValueError(\"Please provide the sample size for conditional analysis.\")\n        else:\n            lead_snp = self.indep_snps_by_conditional(\n                sumstats,\n                ldref,\n                sample_size,\n                sig_threshold,\n                cojo_window_kb,\n                cojo_collinear,\n                diff_freq,\n                use_ref_EAF,\n                only_use_sig_snps,\n                ldblock,\n                threads,\n            )\n    else:\n        raise ValueError(f\"Unsupported method: {method}\")\n    loci = self.leadsnp2loci(lead_snp, loci_extend, if_merge, ldblock)\n    if if_merge and ColName.COJO_BETA in lead_snp.columns:\n        self.logger.warning(\"The loci identified by cojo may not need merge.\")\n        lead_snp = lead_snp[lead_snp[ColName.SNPID].isin(loci[ColName.LEAD_SNP])]\n    if outprefix:\n        loci_file = f\"{outprefix}.loci.txt\"\n        loci.to_csv(loci_file, sep=\"\\t\", index=False, float_format=\"%.6g\")\n        self.logger.info(f\"Save {len(loci)} independent loci to {loci_file}\")\n        leadsnp_file = f\"{outprefix}.leadsnp.txt\"\n        lead_snp.to_csv(leadsnp_file, sep=\"\\t\", index=False, float_format=\"%.6g\")\n        self.logger.info(f\"Save {len(lead_snp)} independent lead snps to {leadsnp_file}\")\n    return lead_snp, loci\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.indep_snps_by_conditional","title":"<code>indep_snps_by_conditional(sumstats, ldref, sample_size, sig_threshold=5e-08, cojo_window_kb=10000, cojo_collinear=0.9, diff_freq=0.2, use_ref_EAF=False, only_use_sig_snps=False, ldblock=None, threads=1)</code>  <code>staticmethod</code>","text":"<p>Identify the independent snps by conditional analysis.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>The summary statistics.</p> required <code>ldref</code> <code>str</code> <p>The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.</p> required <code>sample_size</code> <code>int</code> <p>The sample size.</p> required <code>sig_threshold</code> <code>float</code> <p>The significance threshold, by default 5e-8</p> <code>5e-08</code> <code>cojo_window_kb</code> <code>int</code> <p>The cojo window, by default 10000, in kb</p> <code>10000</code> <code>cojo_collinear</code> <code>float</code> <p>The cojo collinear, by default 0.9</p> <code>0.9</code> <code>diff_freq</code> <code>float</code> <p>The difference frequency, by default 0.2</p> <code>0.2</code> <code>use_ref_EAF</code> <code>bool</code> <p>Whether to use the reference EAF, by default False</p> <code>False</code> <code>only_use_sig_snps</code> <code>bool</code> <p>Whether to only use the significant snps, by default False</p> <code>False</code> <code>ldblock</code> <code>Optional[DataFrame]</code> <p>The LD block, run cojo in each LD block, by default None</p> <code>None</code> <code>threads</code> <code>int</code> <p>The number of threads, by default 1</p> <code>1</code> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef indep_snps_by_conditional(\n    sumstats: pd.DataFrame,\n    ldref: str,\n    sample_size: int,\n    sig_threshold: float = 5e-8,\n    cojo_window_kb: int = 10000,\n    cojo_collinear: float = 0.9,\n    diff_freq: float = 0.2,\n    use_ref_EAF: bool = False,\n    only_use_sig_snps: bool = False,\n    ldblock: Optional[pd.DataFrame] = None,\n    threads: int = 1,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Identify the independent snps by conditional analysis.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        The summary statistics.\n    ldref : str\n        The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.\n    sample_size : int\n        The sample size.\n    sig_threshold : float, optional\n        The significance threshold, by default 5e-8\n    cojo_window_kb : int, optional\n        The cojo window, by default 10000, in kb\n    cojo_collinear : float, optional\n        The cojo collinear, by default 0.9\n    diff_freq : float, optional\n        The difference frequency, by default 0.2\n    use_ref_EAF : bool, optional\n        Whether to use the reference EAF, by default False\n    only_use_sig_snps : bool, optional\n        Whether to only use the significant snps, by default False\n    ldblock : Optional[pd.DataFrame], optional\n        The LD block, run cojo in each LD block, by default None\n    threads : int, optional\n        The number of threads, by default 1\n    \"\"\"\n    logger = logging.getLogger('COJO')\n    if not use_ref_EAF and ColName.EAF not in sumstats.columns:\n        raise ValueError(f\"{ColName.EAF} is not in the sumstats, please set use_ref_EAF to True\")\n    sig_df = sumstats[sumstats[ColName.P] &lt;= sig_threshold]\n    logger.debug(f\"Number of significant snps: {len(sig_df)}\")\n    logger.debug(f\"Number of chromosomes: {len(sig_df[ColName.CHR].unique())}\")\n    args_list = []\n    loci = Loci()\n    if ldblock is not None:\n        sig_blocks = loci.indep_snps_by_distance(sig_df, ldblock=ldblock)\n        sig_blocks = loci.leadsnp2loci(sig_blocks, ldblock=ldblock)\n        for i in sig_blocks.index:\n            if only_use_sig_snps:\n                in_df = sig_df[\n                    (sig_df[ColName.CHR] == sig_blocks.loc[i][ColName.CHR])\n                    &amp; (sig_df[ColName.BP] &gt;= sig_blocks.loc[i][ColName.START])\n                    &amp; (sig_df[ColName.BP] &lt;= sig_blocks.loc[i][ColName.END])\n                ]\n            else:\n                in_df = sumstats[\n                    (sumstats[ColName.CHR] == sig_blocks.loc[i][ColName.CHR])\n                    &amp; (sumstats[ColName.BP] &gt;= sig_blocks.loc[i][ColName.START])\n                    &amp; (sumstats[ColName.BP] &lt;= sig_blocks.loc[i][ColName.END])\n                ]\n            args_list.append(\n                (\n                    in_df,\n                    ldref.format(chrom=sig_blocks.loc[i][ColName.CHR]),\n                    sample_size,\n                    cojo_window_kb,\n                    cojo_collinear,\n                    diff_freq,\n                    sig_threshold,\n                    use_ref_EAF,\n                )\n            )\n    else:\n        for chrom in sig_df[ColName.CHR].unique():\n            if only_use_sig_snps:\n                in_df = sig_df[sig_df[ColName.CHR] == chrom]\n            else:\n                in_df = sumstats[sumstats[ColName.CHR] == chrom]\n            args_list.append(\n                (\n                    in_df,\n                    ldref.format(chrom=chrom),\n                    sample_size,\n                    cojo_window_kb,\n                    cojo_collinear,\n                    diff_freq,\n                    sig_threshold,\n                    use_ref_EAF,\n                )\n            )\n\n    with ProcessPoolExecutor(max_workers=threads) as executor:\n        results = []\n        with Progress(\n            TextColumn(\"{task.description}\"),\n            BarColumn(),\n            MofNCompleteColumn(),\n            TimeElapsedColumn(),\n            auto_refresh=True,\n        ) as progress:\n            task = progress.add_task(\"Run cojo-slct\", total=len(args_list))\n            for _ in executor.map(loci.cojo_slct, *zip(*args_list)):\n                progress.update(task, advance=1)\n                progress.refresh()\n                results.append(_)\n    cojo_snps = pd.concat(results, axis=0, ignore_index=True)\n    return cojo_snps\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.indep_snps_by_distance","title":"<code>indep_snps_by_distance(sig_df, distance=500, ldblock=None)</code>  <code>staticmethod</code>","text":"<p>Identify the independent snps by distance only.</p> <p>Parameters:</p> Name Type Description Default <code>sig_df</code> <code>DataFrame</code> <p>The significant snps.</p> required <code>distance</code> <code>int</code> <p>The distance threshold, by default 500, unit: kb</p> <code>500</code> <code>ldblock</code> <code>Optional[DataFrame]</code> <p>The ld block information, use boundary to identify the independent snps, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The independent snps.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef indep_snps_by_distance(\n    sig_df: pd.DataFrame, distance: int = 500, ldblock: Optional[pd.DataFrame] = None\n) -&gt; pd.DataFrame:\n\"\"\"\n    Identify the independent snps by distance only.\n\n    Parameters\n    ----------\n    sig_df : pd.DataFrame\n        The significant snps.\n    distance : int, optional\n        The distance threshold, by default 500, unit: kb\n    ldblock : Optional[pd.DataFrame], optional\n        The ld block information, use boundary to identify the independent snps, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The independent snps.\n    \"\"\"\n    sig_df = sig_df.sort_values(ColName.P).copy()\n    lead_snp = []\n    if ldblock is not None:\n        while len(sig_df):\n            lead_snp.append(sig_df.iloc[[0]])\n            sig_block = ldblock[\n                (ldblock[ColName.CHR] == sig_df.iloc[0][ColName.CHR])\n                &amp; (ldblock[ColName.START] &lt;= sig_df.iloc[0][ColName.BP])\n                &amp; (ldblock[ColName.END] &gt;= sig_df.iloc[0][ColName.BP])\n            ]\n            sig_df = sig_df[\n                ~(\n                    (sig_df[ColName.CHR] == sig_df.iloc[0][ColName.CHR])\n                    &amp; (sig_df[ColName.BP] &gt;= sig_block.iloc[0][ColName.START])\n                    &amp; (sig_df[ColName.BP] &lt;= sig_block.iloc[0][ColName.END])\n                )\n            ]\n    else:\n        distance = distance * 1000\n        while len(sig_df):\n            lead_snp.append(sig_df.iloc[[0]])\n            sig_df = sig_df[\n                ~(\n                    (sig_df[ColName.CHR] == sig_df.iloc[0][ColName.CHR])\n                    &amp; (sig_df[ColName.BP] &gt;= sig_df.iloc[0][ColName.BP] - distance)\n                    &amp; (sig_df[ColName.BP] &lt;= sig_df.iloc[0][ColName.BP] + distance)\n                )\n            ]  # type: ignore\n    lead_snp = pd.concat(lead_snp, axis=0, ignore_index=True)\n    return lead_snp\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.indep_snps_by_ldclumping","title":"<code>indep_snps_by_ldclumping(sig_df, ldref, clump_p1=5e-08, clump_kb=500, clump_r2=0.1)</code>  <code>staticmethod</code>","text":"<p>Identify the independent snps by LD clumping.</p> <p>Parameters:</p> Name Type Description Default <code>sig_df</code> <code>DataFrame</code> <p>The significant snps.</p> required <code>ldref</code> <code>str</code> <p>The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.</p> required <code>clump_p1</code> <code>float</code> <p>The p1 threshold, by default 5e-8</p> <code>5e-08</code> <code>clump_kb</code> <code>int</code> <p>The kb threshold, by default 500, unit: kb</p> <code>500</code> <code>clump_r2</code> <code>float</code> <p>The r2 threshold, by default 0.1</p> <code>0.1</code> <p>Returns:</p> Type Description <code>DataFrame</code> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef indep_snps_by_ldclumping(\n    sig_df: pd.DataFrame, ldref: str, clump_p1: float = 5e-8, clump_kb: int = 500, clump_r2: float = 0.1\n) -&gt; pd.DataFrame:\n\"\"\"\n    Identify the independent snps by LD clumping.\n\n    Parameters\n    ----------\n    sig_df : pd.DataFrame\n        The significant snps.\n    ldref : str\n        The LD reference file, (plink bfile format, containing wildcard {chrom}), e.g. EUR.chr{chrom}.\n    clump_p1 : float, optional\n        The p1 threshold, by default 5e-8\n    clump_kb : int, optional\n        The kb threshold, by default 500, unit: kb\n    clump_r2 : float, optional\n        The r2 threshold, by default 0.1\n\n    Returns\n    -------\n    pd.DataFrame\n    \"\"\"\n    clumped_snps = []\n    for chrom in sig_df[ColName.CHR].unique():\n        sig_df_chr = sig_df[sig_df[ColName.CHR] == chrom]\n        clumped_snps.append(Loci().clump_per_chr(sig_df_chr, ldref, clump_p1, clump_kb, clump_r2))  # type: ignore\n    clumped_snps = pd.concat(clumped_snps, axis=0, ignore_index=True)\n    return clumped_snps\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.leadsnp2loci","title":"<code>leadsnp2loci(lead_snps, range=500, if_merge=False, ldblock=None)</code>  <code>staticmethod</code>","text":"<p>Expand the independent lead snps to independent loci by given range.</p> <p>Parameters:</p> Name Type Description Default <code>lead_snps</code> <code>DataFrame</code> <p>The independent lead snps.</p> required <code>range</code> <code>int</code> <p>The range, by default 500, unit: kb</p> <code>500</code> <code>if_merge</code> <code>bool</code> <p>Whether merge the overlapped loci, by default False</p> <code>False</code> <code>ldblock</code> <code>Optional[DataFrame]</code> <p>The ld block, using LD block to expand the independent loci, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The independent loci.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef leadsnp2loci(\n    lead_snps: pd.DataFrame, range: int = 500, if_merge: bool = False, ldblock: Optional[pd.DataFrame] = None\n) -&gt; pd.DataFrame:\n\"\"\"\n    Expand the independent lead snps to independent loci by given range.\n\n    Parameters\n    ----------\n    lead_snps : pd.DataFrame\n        The independent lead snps.\n    range : int, optional\n        The range, by default 500, unit: kb\n    if_merge : bool, optional\n        Whether merge the overlapped loci, by default False\n    ldblock : Optional[pd.DataFrame], optional\n        The ld block, using LD block to expand the independent loci, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        The independent loci.\n    \"\"\"\n    loci_df = lead_snps.copy()\n    loci_df = loci_df[[ColName.CHR, ColName.BP, ColName.P, ColName.SNPID]]\n    loci_df.columns = [ColName.CHR, ColName.LEAD_SNP_BP, ColName.LEAD_SNP_P, ColName.LEAD_SNP]  # type: ignore\n    if ldblock is not None:\n        loci_df[ColName.START] = 0\n        loci_df[ColName.END] = 0\n        for i in loci_df.index:\n            sub_ldblock = ldblock[\n                (ldblock[ColName.CHR] == loci_df.loc[i, ColName.CHR])\n                &amp; (ldblock[ColName.START] &lt;= loci_df.loc[i, ColName.LEAD_SNP_BP])\n                &amp; (ldblock[ColName.END] &gt;= loci_df.loc[i, ColName.LEAD_SNP_BP])\n            ]\n            if sub_ldblock.empty:\n                continue\n            else:\n                loci_df.loc[i, ColName.START] = sub_ldblock.iloc[0][ColName.START]\n                loci_df.loc[i, ColName.END] = sub_ldblock.iloc[0][ColName.END]\n    else:\n        range = range * 1000\n\n        loci_df[ColName.START] = loci_df[ColName.LEAD_SNP_BP] - range\n        loci_df[ColName.START] = loci_df[ColName.START].apply(lambda x: 0 if x &lt; 0 else x)\n        loci_df[ColName.END] = loci_df[ColName.LEAD_SNP_BP] + range\n    loci_df = loci_df[ColName.loci_cols].copy()\n    if if_merge:\n        loci_df = Loci.merge_overlapped_loci(loci_df)\n    loci_df = loci_df.sort_values(by=[ColName.CHR, ColName.START, ColName.END])\n    return loci_df\n</code></pre>"},{"location":"api/Loci/#easyfinemap.Loci.merge_overlapped_loci","title":"<code>merge_overlapped_loci(loci_df)</code>  <code>staticmethod</code>","text":"<p>Merge the overlapped loci.</p> <p>Parameters:</p> Name Type Description Default <code>loci_df</code> <code>DataFrame</code> <p>The independent loci.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The merged independent loci.</p> Source code in <code>easyfinemap/loci.py</code> <pre><code>@staticmethod\ndef merge_overlapped_loci(loci_df: pd.DataFrame):\n\"\"\"\n    Merge the overlapped loci.\n\n    Parameters\n    ----------\n    loci_df : pd.DataFrame\n        The independent loci.\n\n    Returns\n    -------\n    pd.DataFrame\n        The merged independent loci.\n    \"\"\"\n    merged_loci = loci_df.copy()\n    merged_loci.sort_values([ColName.CHR, ColName.START, ColName.END], inplace=True)\n    merged_loci['no_overlap'] = merged_loci[ColName.START] &gt; merged_loci[ColName.END].shift().cummax()\n    merged_loci['diff_chr'] = merged_loci[ColName.CHR] != merged_loci[ColName.CHR].shift()\n    merged_loci[\"break\"] = merged_loci[\"no_overlap\"] | merged_loci['diff_chr']\n    merged_loci['group'] = merged_loci['break'].cumsum()\n    merged_loci = merged_loci.sort_values(['group', ColName.LEAD_SNP_P], ascending=True)\n    agg_func = {}\n    for col in loci_df.columns:\n        if col == ColName.START:\n            agg_func[col] = 'min'\n        elif col == ColName.END:\n            agg_func[col] = 'max'\n        else:\n            agg_func[col] = 'first'\n    result = merged_loci.groupby(\"group\").agg(agg_func)\n    result.reset_index(drop=True, inplace=True)\n    return result\n</code></pre>"},{"location":"api/cli/","title":"CLI","text":"<p>Console script for easy_finemap.</p>"},{"location":"api/cli/#easyfinemap.cli.FinemapMethod","title":"<code>FinemapMethod</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>The method to perform fine-mapping.</p>"},{"location":"api/cli/#easyfinemap.cli.LociMethod","title":"<code>LociMethod</code>","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>The method to identify the lead SNPs.</p>"},{"location":"api/cli/#easyfinemap.cli.fine_mapping","title":"<code>fine_mapping(sumstats_path=typer.Argument(..., help='The path to the GWAS summary statistics file.'), loci_path=typer.Argument(..., help='The path to the loci file, generated by get-loci command.'), lead_snps_path=typer.Argument(..., help='The path to the lead SNPs file, generated by get-loci command.'), methods=typer.Option(..., '--methods', '-m', help='The methods to use.'), outfile=typer.Argument(..., help='The output file.'), var_prior=typer.Option(0.5, '--var-prior', help='The prior variance for the aBF method.'), conditional=typer.Option(False, '--conditional', '-c', help='Whether to use conditional mode.'), prior_file=typer.Option(None, '--prior-file', help='The path to the prior file.'), sample_size=typer.Option(None, '--sample-size', '-n', help='The sample size for conditional mode.'), ldref=typer.Option(None, '--ldref', help='The path to the LD reference file.'), cond_snps_wind_kb=typer.Option(10000, '--cond-snps-wind-kb', help='The conditional SNPs window size, in kb.'), max_causal=typer.Option(1, '--max-causal', help='The maximum number of causal SNPs.'), credible_threshold=typer.Option(None, '--credible-threshold', help='The credible threshold.'), credible_method=typer.Option(None, '--credible-method', help='The fine-mapping method for credible set.'), use_ref_EAF=typer.Option(False, '--use-ref-eaf', help='Whether to use the reference panel EAF.'), threads=typer.Option(1, '--threads', '-t', help='The number of threads.'))</code>","text":"<p>Fine mapping.</p> Source code in <code>easyfinemap/cli.py</code> <pre><code>@app.command()\ndef fine_mapping(\n    sumstats_path: str = typer.Argument(..., help=\"The path to the GWAS summary statistics file.\"),\n    loci_path: str = typer.Argument(..., help=\"The path to the loci file, generated by get-loci command.\"),\n    lead_snps_path: str = typer.Argument(..., help=\"The path to the lead SNPs file, generated by get-loci command.\"),\n    methods: List[FinemapMethod] = typer.Option(..., \"--methods\", \"-m\", help=\"The methods to use.\"),\n    outfile: str = typer.Argument(..., help=\"The output file.\"),\n    var_prior: float = typer.Option(0.5, \"--var-prior\", help=\"The prior variance for the aBF method.\"),\n    conditional: bool = typer.Option(False, \"--conditional\", \"-c\", help=\"Whether to use conditional mode.\"),\n    prior_file: Optional[str] = typer.Option(None, \"--prior-file\", help=\"The path to the prior file.\"),\n    sample_size: Optional[int] = typer.Option(\n        None, \"--sample-size\", \"-n\", help=\"The sample size for conditional mode.\"\n    ),\n    ldref: str = typer.Option(None, \"--ldref\", help=\"The path to the LD reference file.\"),\n    cond_snps_wind_kb: int = typer.Option(\n        10000, \"--cond-snps-wind-kb\", help=\"The conditional SNPs window size, in kb.\"\n    ),\n    max_causal: int = typer.Option(1, \"--max-causal\", help=\"The maximum number of causal SNPs.\"),\n    credible_threshold: Optional[float] = typer.Option(None, \"--credible-threshold\", help=\"The credible threshold.\"),\n    credible_method: Optional[str] = typer.Option(\n        None, \"--credible-method\", help=\"The fine-mapping method for credible set.\"\n    ),\n    use_ref_EAF: bool = typer.Option(False, \"--use-ref-eaf\", help=\"Whether to use the reference panel EAF.\"),\n    threads: int = typer.Option(1, \"--threads\", \"-t\", help=\"The number of threads.\"),\n) -&gt; None:\n\"\"\"Fine mapping.\"\"\"\n    if os.path.exists(sumstats_path) and os.path.exists(loci_path) and os.path.exists(lead_snps_path):\n        # sumstats = pd.read_csv(sumstats_path, sep=\"\\t\")\n        loci = pd.read_csv(loci_path, sep=\"\\t\")\n        lead_snps = pd.read_csv(lead_snps_path, sep=\"\\t\")\n        EasyFinemap().finemap_all_loci(\n            sumstats=sumstats_path,\n            loci=loci,\n            lead_snps=lead_snps,\n            methods=methods,  # type: ignore\n            outfile=outfile,\n            var_prior=var_prior,\n            conditional=conditional,\n            prior_file=prior_file,\n            sample_size=sample_size,\n            ldref=ldref,\n            cond_snps_wind_kb=cond_snps_wind_kb,\n            max_causal=max_causal,\n            credible_threshold=credible_threshold,\n            credible_method=credible_method,\n            use_ref_EAF=use_ref_EAF,\n            threads=threads,\n        )\n    else:\n        logging.error(f\"No such file of {sumstats_path} or {loci_path} or {lead_snps_path}.\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#easyfinemap.cli.get_loci","title":"<code>get_loci(sumstats_path=typer.Argument(..., help='The path to the GWAS summary statistics file.'), output=typer.Argument(..., help='The output prefix.'), sig_threshold=typer.Option(5e-08, '--sig-threshold', '-s', help='The significance threshold.'), loci_extension=typer.Option(500, '--loci-extension', '-l', help='The extension from lead SNPs, in kb'), ldblock=typer.Option(None, '--ldblock', help='The path to the LD block file.'), if_merge=typer.Option(False, '--merge-loci', '-i', help='Whether to merge the loci, not recommanded for conditional mode.'), method=typer.Option(LociMethod.distance, '--method', '-m', help='The method to identify the lead SNPs.'), distance=typer.Option(50, '--distance', '-d', help='The distance threshold for distance method, in kb.'), ldref=typer.Option(None, '--ldref', help='The path to the LD reference file.'), clump_kb=typer.Option(500, '--clump-kb', '-c', help='The clumping window size, in kb.'), clump_r2=typer.Option(0.1, '--clump-r2', '-r', help='The clumping r2 threshold.'), sample_size=typer.Option(None, '--sample-size', '-n', help='The sample size for conditional method.'), cojo_window_kb=typer.Option(10000, '--cojo-window-kb', help='The cojo window size, in kb.'), cojo_collinear=typer.Option(0.9, '--cojo-collinear', help='The cojo collinear threshold.'), diff_freq=typer.Option(0.2, '--diff-freq', help='The difference in allele frequency threshold.'), use_ref_eaf=typer.Option(False, '--use-ref-eaf', help='Whether to use the reference panel EAF.'), only_use_sig_snps=typer.Option(False, '--only-use-sig-snps', help='Whether to only use the significant SNPs.'), threads=typer.Option(1, '--threads', '-t', help='The number of threads.'))</code>","text":"<p>Get the loci from the GWAS summary statistics file.</p> Source code in <code>easyfinemap/cli.py</code> <pre><code>@app.command()\ndef get_loci(\n    sumstats_path: Path = typer.Argument(..., help=\"The path to the GWAS summary statistics file.\"),\n    output: str = typer.Argument(..., help=\"The output prefix.\"),\n    sig_threshold: float = typer.Option(5e-8, \"--sig-threshold\", \"-s\", help=\"The significance threshold.\"),\n    loci_extension: int = typer.Option(500, \"--loci-extension\", \"-l\", help=\"The extension from lead SNPs, in kb\"),\n    ldblock: str = typer.Option(None, \"--ldblock\", help=\"The path to the LD block file.\"),\n    if_merge: bool = typer.Option(\n        False, \"--merge-loci\", \"-i\", help=\"Whether to merge the loci, not recommanded for conditional mode.\"\n    ),\n    method: LociMethod = typer.Option(\n        LociMethod.distance, \"--method\", \"-m\", help=\"The method to identify the lead SNPs.\"\n    ),\n    distance: int = typer.Option(50, \"--distance\", \"-d\", help=\"The distance threshold for distance method, in kb.\"),\n    ldref: str = typer.Option(None, \"--ldref\", help=\"The path to the LD reference file.\"),\n    clump_kb: int = typer.Option(500, \"--clump-kb\", \"-c\", help=\"The clumping window size, in kb.\"),\n    clump_r2: float = typer.Option(0.1, \"--clump-r2\", \"-r\", help=\"The clumping r2 threshold.\"),\n    sample_size: int = typer.Option(None, \"--sample-size\", \"-n\", help=\"The sample size for conditional method.\"),\n    cojo_window_kb: int = typer.Option(10000, \"--cojo-window-kb\", help=\"The cojo window size, in kb.\"),\n    cojo_collinear: float = typer.Option(0.9, \"--cojo-collinear\", help=\"The cojo collinear threshold.\"),\n    diff_freq: float = typer.Option(0.2, \"--diff-freq\", help=\"The difference in allele frequency threshold.\"),\n    use_ref_eaf: bool = typer.Option(False, \"--use-ref-eaf\", help=\"Whether to use the reference panel EAF.\"),\n    only_use_sig_snps: bool = typer.Option(\n        False, \"--only-use-sig-snps\", help=\"Whether to only use the significant SNPs.\"\n    ),\n    threads: int = typer.Option(1, \"--threads\", \"-t\", help=\"The number of threads.\"),\n) -&gt; None:\n\"\"\"Get the loci from the GWAS summary statistics file.\"\"\"\n    if sumstats_path.exists():\n        logging.info(f\"Loading {sumstats_path}...\")\n        sumstats = pd.read_csv(sumstats_path, sep=\"\\t\")\n        Loci().identify_indep_loci(\n            sumstats=sumstats,\n            sig_threshold=sig_threshold,\n            loci_extend=loci_extension,\n            ldblock=ldblock,\n            if_merge=if_merge,\n            outprefix=output,\n            ldref=ldref,\n            method=method,\n            distance=distance,\n            clump_kb=clump_kb,\n            clump_r2=clump_r2,\n            sample_size=sample_size,\n            cojo_window_kb=cojo_window_kb,\n            cojo_collinear=cojo_collinear,\n            diff_freq=diff_freq,\n            use_ref_EAF=use_ref_eaf,\n            only_use_sig_snps=only_use_sig_snps,\n            threads=threads,\n        )\n    else:\n        logging.error(f\"No such file of {sumstats_path}.\")\n        sys.exit(1)\n</code></pre>"},{"location":"api/cli/#easyfinemap.cli.main","title":"<code>main(version=typer.Option(False, '--version', '-V', help='Show version.'), verbose=typer.Option(False, '--verbose', '-v', help='Show verbose info.'))</code>","text":"Source code in <code>easyfinemap/cli.py</code> <pre><code>@app.callback(invoke_without_command=True, no_args_is_help=True)\ndef main(\n    version: bool = typer.Option(False, '--version', '-V', help='Show version.'),\n    verbose: bool = typer.Option(False, '--verbose', '-v', help='Show verbose info.'),\n):\n\"\"\"EasyFinemap: A user-friendly tool for fine-mapping.\"\"\"\n    console = Console()\n    console.rule(\"[bold blue]EasyFinemap[/bold blue]\")\n    console.print(f\"Version: {__version__}\", justify=\"center\")\n    console.print(\"Author: Jianhua Wang\", justify=\"center\")\n    console.print(\"Email: jianhua.mert@gmail.com\", justify=\"center\")\n    if version:\n        typer.echo(f'EasyFinemap version: {__version__}')\n        raise typer.Exit()\n    if verbose:\n        logging.getLogger().setLevel(logging.DEBUG)\n        logging.info('Verbose mode is on.')\n    else:\n        logging.getLogger().setLevel(logging.INFO)\n</code></pre>"},{"location":"api/cli/#easyfinemap.cli.validate_ldref","title":"<code>validate_ldref(ldref_path=typer.Argument(..., help='The path to the LD reference file.'), outprefix=typer.Argument(..., help='The output prefix.'), file_type=typer.Option('plink', '--file-type', '-f', help='The file type of the LD reference file.'), mac=typer.Option(10, '--mac', '-m', help='The minor allele count threshold.'), threads=typer.Option(1, '--threads', '-t', help='The number of threads.'))</code>","text":"<p>Validate the LD reference file.</p> Source code in <code>easyfinemap/cli.py</code> <pre><code>@app.command()\ndef validate_ldref(\n    ldref_path: str = typer.Argument(..., help=\"The path to the LD reference file.\"),\n    outprefix: str = typer.Argument(..., help=\"The output prefix.\"),\n    file_type: str = typer.Option(\"plink\", \"--file-type\", \"-f\", help=\"The file type of the LD reference file.\"),\n    mac: int = typer.Option(10, \"--mac\", \"-m\", help=\"The minor allele count threshold.\"),\n    threads: int = typer.Option(1, \"--threads\", \"-t\", help=\"The number of threads.\"),\n) -&gt; None:\n\"\"\"Validate the LD reference file.\"\"\"\n    ld = LDRef()\n    ld.valid(ldref_path, outprefix, file_type, mac, threads)\n</code></pre>"},{"location":"api/easyfinemap/","title":"EasyFinemap","text":"<p>             Bases: <code>object</code></p> <p>Main class.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize.\"\"\"\n    self.logger = logging.getLogger('EasyFinemap')\n    tool = Tools()\n    self.finemap = tool.finemap\n    self.paintor = tool.paintor\n    self.gcta = tool.gcta\n    self.plink = tool.plink\n    self.bcftools = tool.bcftools\n    self.caviarbf = tool.caviarbf\n    self.model_search = tool.model_search\n    self.tmp_root = Path.cwd() / \"tmp\" / \"easyfinemap\"\n    if not self.tmp_root.exists():\n        self.tmp_root.mkdir(parents=True)\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.annotate_prior","title":"<code>annotate_prior(sumstats, prior_file)</code>","text":"<p>Annotate prior from polyfun results.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>prior_file</code> <code>str</code> <p>Path to prior file, present only support polyfun's results: https://github.com/omerwe/polyfun/blob/master/snpvar_meta.chr1_7.parquet https://github.com/omerwe/polyfun/blob/master/snpvar_meta.chr1_7.parquet</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Annotated summary statistics.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def annotate_prior(\n    self,\n    sumstats: pd.DataFrame,\n    prior_file: str,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Annotate prior from polyfun results.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    prior_file : str\n        Path to prior file, present only support polyfun's results:\n        https://github.com/omerwe/polyfun/blob/master/snpvar_meta.chr1_7.parquet\n        https://github.com/omerwe/polyfun/blob/master/snpvar_meta.chr1_7.parquet\n\n    Returns\n    -------\n    pd.DataFrame\n        Annotated summary statistics.\n    \"\"\"\n    # check tabix index\n    if not os.path.exists(f\"{prior_file}.tbi\"):\n        raise ValueError(f\"No tabix index for {prior_file}\")\n    # check header\n    header = pd.read_csv(prior_file, sep=\"\\t\", nrows=0).columns.tolist()\n    if 'snpvar_bin' not in header:\n        raise ValueError(f\"No snpvar_bin in {prior_file}\")\n    # annotate\n    tb = tabix.open(prior_file)\n    chrom = sumstats[ColName.CHR].unique()[0]\n    start = sumstats[ColName.BP].min()\n    end = sumstats[ColName.BP].max()\n    prior_df = pd.DataFrame(data=tb.query(str(chrom), start, end), columns=header)\n    prior_df = prior_df.rename(columns={\"snpvar_bin\": \"SNPVAR\"})\n    prior_df['SNPVAR'] = prior_df['SNPVAR'].astype(float)\n    prior_df = sg.make_SNPID_unique(prior_df, ColName.CHR, ColName.BP, 'A1', 'A2')\n    prior_df = prior_df.drop_duplicates(subset=ColName.SNPID)\n    prior_map = prior_df[['SNPID', 'SNPVAR']].set_index('SNPID').to_dict()['SNPVAR']\n    sumstats['SNPVAR'] = sumstats[ColName.SNPID].map(prior_map).fillna(0)\n    return sumstats\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.cond_sumstat","title":"<code>cond_sumstat(sumstats, lead_snp, lead_snps, ldref, sample_size, use_ref_EAF=False, cond_snps_wind_kb=1000, temp_dir=None, **kwargs)</code>","text":"<p>Conditional sumstat.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>lead_snp</code> <code>str</code> <p>Lead SNP.</p> required <code>ldref</code> <code>str</code> <p>Path to LD reference.</p> required <code>sample_size</code> <code>int</code> <p>Sample size.</p> required <code>use_ref_EAF</code> <code>bool</code> <p>Use reference EAF, by default False</p> <code>False</code> <code>cond_snps_wind_kb</code> <code>int</code> <p>Conditional SNPs window in kb, by default 1000</p> <code>1000</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Path to tempdir, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Conditional sumstat.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef cond_sumstat(\n    self,\n    sumstats: pd.DataFrame,\n    lead_snp: str,\n    lead_snps: pd.DataFrame,\n    ldref: str,\n    sample_size: int,\n    use_ref_EAF: bool = False,\n    cond_snps_wind_kb: int = 1000,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Conditional sumstat.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    lead_snp : str\n        Lead SNP.\n    ldref : str\n        Path to LD reference.\n    sample_size : int\n        Sample size.\n    use_ref_EAF : bool, optional\n        Use reference EAF, by default False\n    cond_snps_wind_kb : int, optional\n        Conditional SNPs window in kb, by default 1000\n    temp_dir : Optional[str], optional\n        Path to tempdir, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        Conditional sumstat.\n    \"\"\"\n    if lead_snp is None:\n        raise ValueError(\"Lead SNP is required for conditional finemapping\")\n    if lead_snps is None:\n        raise ValueError(\"Lead SNPs are required for conditional finemapping\")\n    lead_snp_chr = lead_snps.loc[lead_snps[ColName.SNPID] == lead_snp, ColName.CHR].values[0]\n    lead_snp_bp: int = lead_snps.loc[lead_snps[ColName.SNPID] == lead_snp, ColName.BP].values[0]  # type: ignore\n    cond_snps = lead_snps[\n        (lead_snps[ColName.CHR] == lead_snp_chr)\n        &amp; (lead_snps[ColName.BP] &gt;= lead_snp_bp - cond_snps_wind_kb * 1000)\n        &amp; (lead_snps[ColName.BP] &lt;= lead_snp_bp + cond_snps_wind_kb * 1000)\n        &amp; (lead_snps[ColName.SNPID] != lead_snp)\n    ]\n    if cond_snps.empty:\n        self.logger.debug(f\"No conditional SNPs found for {lead_snp}\")\n        cond_res = sumstats.copy()\n        cond_res[ColName.COJO_BETA] = cond_res[ColName.BETA]\n        cond_res[ColName.COJO_SE] = cond_res[ColName.SE]\n        cond_res[ColName.COJO_P] = cond_res[ColName.P]\n    else:\n        ld = LDRef()\n        chrom = lead_snp_chr\n        cojo_input = ld.intersect(sumstats, ldref, f\"{temp_dir}/cojo_input_{chrom}\", use_ref_EAF)\n        cond_res = ld.cojo_cond(\n            cojo_input, cond_snps, f\"{temp_dir}/cojo_input_{chrom}\", sample_size, use_ref_EAF\n        )  # type: ignore\n    return cond_res\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.finemap_all_loci","title":"<code>finemap_all_loci(sumstats, loci, lead_snps, methods, var_prior=0.2, conditional=False, prior_file=None, sample_size=None, ldref=None, cond_snps_wind_kb=1000, max_causal=1, credible_threshold=None, credible_method=None, use_ref_EAF=False, outfile=None, threads=1)</code>","text":"<p>Perform finemapping for all loci.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>loci</code> <code>DataFrame</code> <p>Loci.</p> required <code>lead_snps</code> <code>DataFrame</code> <p>Lead SNPs.</p> required <code>methods</code> <code>List[str]</code> <p>Finemapping methods.</p> required <code>var_prior</code> <code>float</code> <p>Variance prior, by default 0.2</p> <code>0.2</code> <code>conditional</code> <code>bool</code> <p>Conditional finemapping, by default False</p> <code>False</code> <code>prior_file</code> <code>Optional[str]</code> <p>Path to prior file, by default None</p> <code>None</code> <code>sample_size</code> <code>Optional[int]</code> <p>Sample size, by default None</p> <code>None</code> <code>ldref</code> <code>Optional[str]</code> <p>LD reference, by default None</p> <code>None</code> <code>cond_snps_wind_kb</code> <code>int</code> <p>Conditional SNPs window, by default 1000</p> <code>1000</code> <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>credible_threshold</code> <code>Optional[float]</code> <p>Credible threshold, by default None</p> <code>None</code> <code>credible_method</code> <code>Optional[str]</code> <p>Credible method, by default None</p> <code>None</code> <code>use_ref_EAF</code> <code>bool</code> <p>Use reference EAF, by default False</p> <code>False</code> <code>outfile</code> <code>Optional[str]</code> <p>Output file, by default None</p> <code>None</code> <code>threads</code> <code>int</code> <p>Number of threads, by default 1</p> <code>1</code> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def finemap_all_loci(\n    self,\n    sumstats: pd.DataFrame,\n    loci: pd.DataFrame,\n    lead_snps: pd.DataFrame,\n    methods: List[str],\n    var_prior: float = 0.2,\n    conditional: bool = False,\n    prior_file: Optional[str] = None,\n    sample_size: Optional[int] = None,\n    ldref: Optional[str] = None,\n    cond_snps_wind_kb: int = 1000,\n    max_causal: int = 1,\n    credible_threshold: Optional[float] = None,\n    credible_method: Optional[str] = None,\n    use_ref_EAF: bool = False,\n    outfile: Optional[str] = None,\n    threads: int = 1,\n):\n\"\"\"\n    Perform finemapping for all loci.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    loci : pd.DataFrame\n        Loci.\n    lead_snps : pd.DataFrame\n        Lead SNPs.\n    methods : List[str]\n        Finemapping methods.\n    var_prior : float, optional\n        Variance prior, by default 0.2\n    conditional : bool, optional\n        Conditional finemapping, by default False\n    prior_file : Optional[str], optional\n        Path to prior file, by default None\n    sample_size : Optional[int], optional\n        Sample size, by default None\n    ldref : Optional[str], optional\n        LD reference, by default None\n    cond_snps_wind_kb : int, optional\n        Conditional SNPs window, by default 1000\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    credible_threshold : Optional[float], optional\n        Credible threshold, by default None\n    credible_method : Optional[str], optional\n        Credible method, by default None\n    use_ref_EAF : bool, optional\n        Use reference EAF, by default False\n    outfile : Optional[str], optional\n        Output file, by default None\n    threads : int, optional\n        Number of threads, by default 1\n    \"\"\"\n    # sumstats = sg.make_SNPID_unique(sumstats, ColName.CHR, ColName.BP, ColName.EA, ColName.NEA)\n    if credible_threshold and credible_method is None and methods != [\"all\"] and len(methods) == 1:\n        credible_method = methods[0]\n    kwargs_list = []\n    for chrom, start, end, lead_snp in loci[[ColName.CHR, ColName.START, ColName.END, ColName.LEAD_SNP]].values:\n        locus_sumstats = sg.export_sumstats(sumstats, chrom, start, end)\n        locus_sumstats = sg.make_SNPID_unique(locus_sumstats, ColName.CHR, ColName.BP, ColName.EA, ColName.NEA)\n        kwargs = {\n            \"sumstats\": locus_sumstats,\n            \"lead_snp\": lead_snp,\n            \"lead_snps\": lead_snps,\n            \"methods\": methods,\n            \"var_prior\": var_prior,\n            \"conditional\": conditional,\n            \"prior_file\": prior_file,\n            \"sample_size\": sample_size,\n            \"ldref\": ldref.format(chrom=chrom) if ldref else None,\n            \"cond_snps_wind_kb\": cond_snps_wind_kb,\n            \"max_causal\": max_causal,\n            \"credible_threshold\": credible_threshold,\n            \"credible_method\": credible_method,\n            \"use_ref_EAF\": use_ref_EAF,\n        }\n        kwargs_list.append(kwargs)\n    ef = EasyFinemap()\n    # output = []\n    # with Progress(\n    #     TextColumn(\"{task.description}\"),\n    #     BarColumn(),\n    #     MofNCompleteColumn(),\n    #     TimeElapsedColumn(),\n    #     auto_refresh=True,\n    # ) as progress:\n    #     with Pool(threads) as p:\n    #         task = progress.add_task(\"Perform Fine-mapping...\", total=len(loci))\n    #         results = [p.apply_async(ef.finemap_locus, kwds=kwargs) for kwargs in kwargs_list]\n    #         for res in results:\n    #             progress.update(task, advance=1)\n    #             progress.refresh()\n    #             output.append(res.get())\n    with ProcessPoolExecutor(max_workers=threads) as executor:\n        output = []\n        with Progress(\n            TextColumn(\"{task.description}\"),\n            BarColumn(),\n            MofNCompleteColumn(),\n            TimeElapsedColumn(),\n            auto_refresh=True,\n        ) as progress:\n            task = progress.add_task(\"Perform Fine-mapping...\", total=len(kwargs_list))\n            for _ in executor.map(ef.finemap_locus_parallel, kwargs_list):\n                progress.update(task, advance=1)\n                progress.refresh()\n                output.append(_)\n    output_df = pd.concat(output, ignore_index=True)\n    if outfile:\n        output_df.to_csv(outfile, sep=\"\\t\", index=False, float_format=\"%0.6g\")\n    else:\n        return output_df\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.finemap_locus","title":"<code>finemap_locus(sumstats, methods, lead_snp, conditional=False, prior_file=None, temp_dir=None, **kwargs)</code>","text":"<p>Finemap a locus.</p> <ol> <li>Check if LD is needed, abf does not need LD.</li> <li>If LD is needed, intersect the locus with the LD reference and make the LD matrix.</li> <li>Run the finemapping method.</li> <li>Get the finemapping results.</li> <li>Merge the finemapping results with the input sumstats.</li> <li>Return the credible set or full summary statistics with posterior probabilities.</li> </ol> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>methods</code> <code>List[str]</code> <p>Finemapping methods.</p> required <code>lead_snp</code> <code>str</code> <p>Lead SNP.</p> required <code>conditional</code> <code>bool</code> <p>Conditional finemapping, by default False</p> <code>False</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Temporary directory, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Finemapping results.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef finemap_locus(\n    self,\n    sumstats: pd.DataFrame,\n    methods: List[str],\n    lead_snp: str,\n    conditional: bool = False,\n    prior_file: Optional[str] = None,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Finemap a locus.\n\n    1. Check if LD is needed, abf does not need LD.\n    2. If LD is needed, intersect the locus with the LD reference and make the LD matrix.\n    3. Run the finemapping method.\n    4. Get the finemapping results.\n    5. Merge the finemapping results with the input sumstats.\n    6. Return the credible set or full summary statistics with posterior probabilities.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    methods : List[str]\n        Finemapping methods.\n    lead_snp : str\n        Lead SNP.\n    conditional : bool, optional\n        Conditional finemapping, by default False\n    temp_dir : Optional[str], optional\n        Temporary directory, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        Finemapping results.\n    \"\"\"\n    if conditional:\n        cond_res = self.cond_sumstat(sumstats=sumstats, lead_snp=lead_snp, **kwargs)\n        fm_input = cond_res.copy()\n        fm_input[ColName.BETA] = cond_res[ColName.COJO_BETA]\n        fm_input[ColName.SE] = cond_res[ColName.COJO_SE]\n        fm_input[ColName.P] = cond_res[ColName.COJO_P]\n        out_sumstats = sumstats.merge(\n            cond_res[[ColName.SNPID, ColName.COJO_BETA, ColName.COJO_SE, ColName.COJO_P]],\n            on=ColName.SNPID,\n            how=\"left\",\n        )\n        max_causal = kwargs.get(\"max_causal\", 1)\n        if max_causal &gt; 1:\n            self.logger.warning(\"Conditional finemapping does not support multiple causal variants\")\n    else:\n        fm_input = sumstats.copy()\n        out_sumstats = sumstats.copy()\n\n    allowed_methods = [\"abf\", \"finemap\", \"paintor\", \"caviarbf\", \"susie\", \"polyfun_finemap\", \"polyfun_susie\"]\n    if \"all\" in methods:\n        methods = allowed_methods\n    fm_input_ol = fm_input.copy()\n    if prior_file:\n        fm_input_ol = self.annotate_prior(fm_input_ol, prior_file)\n    for method in methods:\n        if method == \"abf\":\n            abf_pp = self.run_abf(sumstats=fm_input_ol, **kwargs)\n            out_sumstats[ColName.PP_ABF] = out_sumstats[ColName.SNPID].map(abf_pp)\n        elif method in [\"finemap\", \"paintor\", \"caviarbf\", \"susie\", \"polyfun_finemap\", \"polyfun_susie\"]:\n            ld_matrix = f\"{temp_dir}/intersc.ld\"\n            if not os.path.exists(ld_matrix):\n                # TODO: reduce the number of SNPs when using paintor and caviarbf in multiple causal variant mode\n                fm_input_ol = self.prepare_ld_matrix(\n                    sumstats=fm_input_ol, outprefix=f\"{temp_dir}/intersc\", **kwargs\n                )\n            if method == \"finemap\":\n                finemap_pp = self.run_finemap(sumstats=fm_input_ol, ld_matrix=ld_matrix, **kwargs)\n                out_sumstats[ColName.PP_FINEMAP] = out_sumstats[ColName.SNPID].map(finemap_pp)\n            elif method == \"paintor\":\n                paintor_pp = self.run_paintor(sumstats=fm_input_ol, ld_matrix=ld_matrix, **kwargs)\n                out_sumstats[ColName.PP_PAINTOR] = out_sumstats[ColName.SNPID].map(paintor_pp)\n            elif method == \"caviarbf\":\n                caviarbf_pp = self.run_caviarbf(sumstats=fm_input_ol, ld_matrix=ld_matrix, **kwargs)\n                out_sumstats[ColName.PP_CAVIARBF] = out_sumstats[ColName.SNPID].map(caviarbf_pp)\n            elif method == \"susie\":\n                susie_pp = self.run_susie(sumstats=fm_input_ol, ld_matrix=ld_matrix, **kwargs)\n                out_sumstats[ColName.PP_SUSIE] = out_sumstats[ColName.SNPID].map(susie_pp)\n            elif method == \"polyfun_finemap\":\n                polyfun_finemap_pp = self.run_finemap(sumstats=fm_input_ol, ld_matrix=ld_matrix, **kwargs)\n                out_sumstats[ColName.PP_POLYFUN_FINEMAP] = out_sumstats[ColName.SNPID].map(polyfun_finemap_pp)\n            elif method == \"polyfun_susie\":\n                polyfun_susie_pp = self.run_susie(sumstats=fm_input_ol, ld_matrix=ld_matrix, **kwargs)\n                out_sumstats[ColName.PP_POLYFUN_SUSIE] = out_sumstats[ColName.SNPID].map(polyfun_susie_pp)\n        else:\n            raise ValueError(f\"Method {method} is not supported\")\n\n    credible_set = self.get_credset(finemap_res=out_sumstats, **kwargs)\n    credible_set[ColName.LEAD_SNP] = lead_snp\n    return credible_set\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.finemap_locus_parallel","title":"<code>finemap_locus_parallel(kwargs)</code>","text":"<p>Perform finemapping for a locus in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>kwargs</code> <code>dict</code> <p>Keyword arguments.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>Finemapping results.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def finemap_locus_parallel(self, kwargs):\n\"\"\"\n    Perform finemapping for a locus in parallel.\n\n    Parameters\n    ----------\n    kwargs : dict\n        Keyword arguments.\n\n    Returns\n    -------\n    pd.DataFrame\n        Finemapping results.\n    \"\"\"\n    return self.finemap_locus(**kwargs)\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.get_credset","title":"<code>get_credset(finemap_res, max_causal, credible_threshold=None, credible_method=None, **kwargs)</code>","text":"<p>Get credible set.</p> <p>Parameters:</p> Name Type Description Default <code>finemap_res</code> <code>DataFrame</code> <p>Finemap results.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants.</p> required <code>credible_threshold</code> <code>Optional[float]</code> <p>Credible threshold, by default None</p> <code>None</code> <code>credible_method</code> <code>Optional[str]</code> <p>Credible set method, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Credible set.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def get_credset(\n    self,\n    finemap_res: pd.DataFrame,\n    max_causal: int,\n    credible_threshold: Optional[float] = None,\n    credible_method: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Get credible set.\n\n    Parameters\n    ----------\n    finemap_res : pd.DataFrame\n        Finemap results.\n    max_causal : int\n        Maximum number of causal variants.\n    credible_threshold : Optional[float], optional\n        Credible threshold, by default None\n    credible_method : Optional[str], optional\n        Credible set method, by default None\n\n    Returns\n    -------\n    pd.DataFrame\n        Credible set.\n    \"\"\"\n    if credible_threshold is None:\n        return finemap_res\n    else:\n        credible_threshold = credible_threshold * max_causal\n        if credible_method:\n            pp_col = f\"PP_{credible_method.upper()}\"\n            credible_set = finemap_res.sort_values(pp_col, ascending=False)\n            credible_set = finemap_res.sort_values(by=pp_col, ascending=False)\n            credible_set = credible_set[credible_set[pp_col].shift().fillna(0).cumsum() &lt;= credible_threshold]\n        else:\n            raise ValueError(\"Must specify credible set method when credible threshold is specified\")\n    return credible_set.reset_index(drop=True)\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.prepare_ld_matrix","title":"<code>prepare_ld_matrix(sumstats, ldref, outprefix, use_ref_EAF=False, **kwargs)</code>","text":"<p>Prepare LD matrix.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ldref</code> <code>str</code> <p>Path to LD reference.</p> required <code>outprefix</code> <code>str</code> <p>Output prefix.</p> required <code>use_ref_EAF</code> <code>bool</code> <p>Use reference EAF, by default False</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>LD matrix.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def prepare_ld_matrix(\n    self,\n    sumstats: pd.DataFrame,\n    ldref: str,\n    outprefix: str,\n    use_ref_EAF: bool = False,\n    **kwargs,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Prepare LD matrix.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ldref : str\n        Path to LD reference.\n    outprefix : str\n        Output prefix.\n    use_ref_EAF : bool, optional\n        Use reference EAF, by default False\n\n    Returns\n    -------\n    pd.DataFrame\n        LD matrix.\n    \"\"\"\n    if ldref is None:\n        raise ValueError(\"LD reference is required for LD-based finemapping\")\n    ld = LDRef()\n    sumstats_ol = ld.intersect(sumstats, ldref, outprefix, use_ref_EAF)\n    ld.make_ld(outprefix, outprefix)\n    return sumstats_ol\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_abf","title":"<code>run_abf(sumstats, var_prior=0.2, max_causal=1, **kwargs)</code>","text":"<p>Run ABF.</p> <p>calculate the approximate Bayes factor (ABF) from BETA and SE, using the formula: SNP_BF = sqrt(SE/(SE + W^2))EXP(W^2/(SE + W^2)*(BETA^2/SE^2)/2) where W is variance prior, usually set to 0.15 for quantitative traits and 0.2 for binary traits. the posterior probability of each variant being causal is calculated using the formula: PP(causal) = SNP_BF / sum(all_SNP_BFs)</p> <p>Reference: Asimit, J. L. et al. Eur J Hum Genet (2016)</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>var_prior</code> <code>float</code> <p>Variance prior, by default 0.2, usually set to 0.15 for quantitative traits and 0.2 for binary traits.</p> <code>0.2</code> <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of ABF.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>def run_abf(self, sumstats: pd.DataFrame, var_prior: float = 0.2, max_causal: int = 1, **kwargs) -&gt; pd.Series:\n\"\"\"\n    Run ABF.\n\n    calculate the approximate Bayes factor (ABF) from BETA and SE, using the\n    formula:\n    SNP_BF = sqrt(SE/(SE + W^2))EXP(W^2/(SE + W^2)*(BETA^2/SE^2)/2)\n    where W is variance prior, usually set to 0.15 for quantitative traits\n    and 0.2 for binary traits.\n    the posterior probability of each variant being causal is calculated\n    using the formula:\n    PP(causal) = SNP_BF / sum(all_SNP_BFs)\n\n    Reference: Asimit, J. L. et al. Eur J Hum Genet (2016)\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    var_prior : float, optional\n        Variance prior, by default 0.2, usually set to 0.15 for quantitative traits\n        and 0.2 for binary traits.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n\n    Returns\n    -------\n    pd.Series\n        The result of ABF.\n    \"\"\"\n    if max_causal &gt; 1:\n        raise NotImplementedError(\"ABF only support single causal variant.\")\n    df = sumstats.copy()\n    df[\"W2\"] = var_prior**2\n    df[\"SNP_BF\"] = np.sqrt((df[ColName.SE] ** 2 / (df[ColName.SE] ** 2 + df[\"W2\"]))) * np.exp(\n        df[\"W2\"] / (df[ColName.BETA] ** 2 + df[\"W2\"]) * (df[ColName.BETA] ** 2 / df[ColName.SE] ** 2) / 2\n    )\n    df[ColName.PP_ABF] = df[\"SNP_BF\"] / df[\"SNP_BF\"].sum()\n    return pd.Series(data=df[ColName.PP_ABF].values, index=df[ColName.SNPID].tolist())\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_caviarbf","title":"<code>run_caviarbf(sumstats, ld_matrix, max_causal=1, temp_dir=None, **kwargs)</code>","text":"<p>Run CAVIAR-BF.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ld_matrix</code> <code>str</code> <p>Path to LD matrix.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Path to tempdir, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of CAVIAR-BF.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef run_caviarbf(\n    self, sumstats: pd.DataFrame, ld_matrix: str, max_causal: int = 1, temp_dir: Optional[str] = None, **kwargs\n):\n\"\"\"\n    Run CAVIAR-BF.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ld_matrix : str\n        Path to LD matrix.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    temp_dir : Optional[str], optional\n        Path to tempdir, by default None\n\n    Returns\n    -------\n    pd.Series\n        The result of CAVIAR-BF.\n    \"\"\"\n    caviar_input = sumstats.copy()\n    caviar_input[ColName.Z] = caviar_input[ColName.BETA] / caviar_input[ColName.SE]\n    caviar_input[[ColName.SNPID, ColName.Z]].to_csv(f\"{temp_dir}/caviar.input\", sep=\" \", index=False, header=False)\n    n_variants = caviar_input.shape[0]\n    cmd = [\n        self.caviarbf,\n        \"-z\",\n        f\"{temp_dir}/caviar.input\",\n        \"-r\",\n        ld_matrix,\n        \"-t\",\n        \"0\",\n        \"-a\",\n        \"0.1281429\",\n        \"-n\",\n        str(n_variants),\n        \"-c\",\n        str(max_causal),\n        \"-o\",\n        f\"{temp_dir}/caviar.output\",\n    ]\n    self.logger.debug(f\"run CAVIAR-BF: {' '.join(cmd)}\")\n    run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    cmd = [\n        self.model_search,\n        \"-i\",\n        f\"{temp_dir}/caviar.output\",\n        \"-m\",\n        str(n_variants),\n        \"-p\",\n        \"0\",\n        \"-o\",\n        f\"{temp_dir}/caviar.prior0\",\n    ]\n    self.logger.debug(f\"run CAVIAR-BF: {' '.join(cmd)}\")\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        caviar_res = pd.read_csv(f\"{temp_dir}/caviar.prior0.marginal\", sep=\" \", header=None)\n        caviar_res.sort_values(by=0, inplace=True)  # type: ignore\n        caviar_res = pd.Series(caviar_res[1].values, index=caviar_input[ColName.SNPID].tolist())\n        return caviar_res\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_finemap","title":"<code>run_finemap(sumstats, ld_matrix, sample_size, max_causal=1, prior_file=None, temp_dir=None, **kwargs)</code>","text":"<p>Run FINEMAP.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ld_matrix</code> <code>str</code> <p>Path to LD matrix.</p> required <code>sample_size</code> <code>int</code> <p>Sample size.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>prior_file</code> <code>Optional[str]</code> <p>Path to prior file, by default None</p> <code>None</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Path to tempdir, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of FINEMAP.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef run_finemap(\n    self,\n    sumstats: pd.DataFrame,\n    ld_matrix: str,\n    sample_size: int,\n    max_causal: int = 1,\n    prior_file: Optional[str] = None,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.Series:\n\"\"\"\n    Run FINEMAP.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ld_matrix : str\n        Path to LD matrix.\n    sample_size : int\n        Sample size.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    prior_file : Optional[str], optional\n        Path to prior file, by default None\n    temp_dir : Optional[str], optional\n        Path to tempdir, by default None\n\n    Returns\n    -------\n    pd.Series\n        The result of FINEMAP.\n    \"\"\"\n    if ColName.MAF not in sumstats.columns:\n        raise ValueError(f\"{ColName.MAF} is required for FINEMAP.\")\n    finemap_input = sumstats.copy()\n    finemap_input[ColName.MAF] = finemap_input[ColName.MAF].replace(0, 0.00001)\n    if prior_file:\n        finemap_input = finemap_input[\n            [\n                ColName.SNPID,\n                ColName.CHR,\n                ColName.BP,\n                ColName.EA,\n                ColName.NEA,\n                ColName.MAF,\n                ColName.BETA,\n                ColName.SE,\n                'SNPVAR',\n            ]\n        ]\n        finemap_input.rename(\n            columns={\n                ColName.SNPID: \"rsid\",\n                ColName.CHR: \"chromosome\",\n                ColName.BP: \"position\",\n                ColName.MAF: \"maf\",\n                ColName.BETA: \"beta\",\n                ColName.SE: \"se\",\n                ColName.EA: \"allele1\",\n                ColName.NEA: \"allele2\",\n                'SNPVAR': 'prob',\n            },\n            inplace=True,\n        )\n        finemap_input['prob'] = finemap_input['prob'] / finemap_input['prob'].sum()\n    else:\n        finemap_input = finemap_input[\n            [ColName.SNPID, ColName.CHR, ColName.BP, ColName.EA, ColName.NEA, ColName.MAF, ColName.BETA, ColName.SE]\n        ]\n        finemap_input.rename(\n            columns={\n                ColName.SNPID: \"rsid\",\n                ColName.CHR: \"chromosome\",\n                ColName.BP: \"position\",\n                ColName.MAF: \"maf\",\n                ColName.BETA: \"beta\",\n                ColName.SE: \"se\",\n                ColName.EA: \"allele1\",\n                ColName.NEA: \"allele2\",\n            },\n            inplace=True,\n        )\n    finemap_input.to_csv(f\"{temp_dir}/finemap.z\", sep=\" \", index=False, float_format=\"%0.5f\")\n    with open(f\"{temp_dir}/finemap.master\", \"w\") as f:\n        master_content = [\n            f\"{temp_dir}/finemap.z\",\n            ld_matrix,\n            f\"{temp_dir}/finemap.snp\",\n            f\"{temp_dir}/finemap.config\",\n            f\"{temp_dir}/finemap.cred\",\n            f\"{temp_dir}/finemap.log\",\n            str(sample_size),\n        ]\n        f.write(\"z;ld;snp;config;cred;log;n_samples\\n\")\n        f.write(\";\".join(master_content))\n    cmd = [\n        self.finemap,\n        \"--sss\",\n        \"--in-files\",\n        f\"{temp_dir}/finemap.master\",\n        \"--n-causal-snps\",\n        str(max_causal),\n        \"--prior-snps\" if prior_file else \"\",\n    ]\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    self.logger.debug(f\"run FINEMAP: {' '.join(cmd)}\")\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        # if max_causal == 1:\n        finemap_res = pd.read_csv(f\"{temp_dir}/finemap.snp\", sep=\" \", usecols=[\"rsid\", \"prob\"])\n        finemap_res = pd.Series(finemap_res[\"prob\"].values, index=finemap_res[\"rsid\"].values)  # type: ignore\n        # else:\n        #     raise NotImplementedError\n        return finemap_res\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_paintor","title":"<code>run_paintor(sumstats, ld_matrix, max_causal=1, temp_dir=None, **kwargs)</code>","text":"<p>Run PAINTOR.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ld_matrix</code> <code>str</code> <p>Path to LD matrix.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>temp_dir</code> <code>Optional[str]</code> <p>Path to tempdir, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of PAINTOR.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef run_paintor(\n    self, sumstats: pd.DataFrame, ld_matrix: str, max_causal: int = 1, temp_dir: Optional[str] = None, **kwargs\n):\n\"\"\"\n    Run PAINTOR.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ld_matrix : str\n        Path to LD matrix.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    temp_dir : Optional[str], optional\n        Path to tempdir, by default None\n\n    Returns\n    -------\n    pd.Series\n        The result of PAINTOR.\n    \"\"\"\n    paintor_input = sumstats.copy()\n    paintor_input[\"coding\"] = 1  # TODO: support paintor annotation mode\n    paintor_input[\"Zscore\"] = paintor_input[ColName.BETA] / paintor_input[ColName.SE]\n    input_prefix = \"paintor.processed\"\n    paintor_input[[ColName.SNPID, ColName.CHR, ColName.BP, \"Zscore\"]].to_csv(\n        f\"{temp_dir}/{input_prefix}\", sep=\" \", index=False\n    )\n    paintor_input[\"coding\"].to_csv(f\"{temp_dir}/{input_prefix}.annotations\", sep=\" \", index=False, header=True)\n    with open(f\"{temp_dir}/{input_prefix}.input\", \"w\") as f:\n        f.write(input_prefix)\n    ld_matrix_abs_path = os.path.abspath(ld_matrix)\n    run(\n        ['ln', \"-s\", ld_matrix_abs_path, f'{temp_dir}/{input_prefix}.ld'],\n        stdout=PIPE,\n        stderr=PIPE,\n        universal_newlines=True,\n    )\n    cmd = [\n        self.paintor,\n        \"-input\",\n        f\"{temp_dir}/{input_prefix}.input\",\n        \"-out\",\n        temp_dir,\n        \"-Zhead\",\n        \"Zscore\",\n        \"-LDname\",\n        \"ld\",\n        \"-enumerate\",\n        str(max_causal),\n        \"-in\",\n        temp_dir,\n    ]\n    self.logger.debug(f\"run PAINTOR: {' '.join(cmd)}\")\n    res = run(cmd, stdout=PIPE, stderr=PIPE, universal_newlines=True)\n    if res.returncode != 0:\n        self.logger.error(res.stderr)\n        raise RuntimeError(res.stderr)\n    else:\n        paintor_res = pd.read_csv(\n            f\"{temp_dir}/paintor.processed.results\", sep=\" \", usecols=[\"SNPID\", \"Posterior_Prob\"]\n        )\n        paintor_res = pd.Series(paintor_res[\"Posterior_Prob\"].values, index=paintor_res[\"SNPID\"].tolist())\n        return paintor_res\n</code></pre>"},{"location":"api/easyfinemap/#easyfinemap.EasyFinemap.run_susie","title":"<code>run_susie(sumstats, ld_matrix, sample_size, max_causal=1, prior_file=None, temp_dir=None, **kwargs)</code>","text":"<p>Run SuSiE.</p> <p>Parameters:</p> Name Type Description Default <code>sumstats</code> <code>DataFrame</code> <p>Summary statistics.</p> required <code>ld_matrix</code> <code>str</code> <p>Path to LD matrix.</p> required <code>sample_size</code> <code>int</code> <p>Sample size.</p> required <code>max_causal</code> <code>int</code> <p>Maximum number of causal variants, by default 1</p> <code>1</code> <code>prior_file</code> <code>Optional[str]</code> <p>Path to prior file, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Series</code> <p>The result of SuSiE.</p> Source code in <code>easyfinemap/easyfinemap.py</code> <pre><code>@io_in_tempdir('./tmp/easyfinemap')\ndef run_susie(\n    self,\n    sumstats: pd.DataFrame,\n    ld_matrix: str,\n    sample_size: int,\n    max_causal: int = 1,\n    prior_file: Optional[str] = None,\n    temp_dir: Optional[str] = None,\n    **kwargs,\n) -&gt; pd.Series:\n\"\"\"\n    Run SuSiE.\n\n    Parameters\n    ----------\n    sumstats : pd.DataFrame\n        Summary statistics.\n    ld_matrix : str\n        Path to LD matrix.\n    sample_size : int\n        Sample size.\n    max_causal : int, optional\n        Maximum number of causal variants, by default 1\n    prior_file : Optional[str], optional\n        Path to prior file, by default None\n\n    Returns\n    -------\n    pd.Series\n        The result of SuSiE.\n    \"\"\"\n    susie_input = sumstats.copy()\n    susie_input[ColName.Z] = susie_input[ColName.BETA] / susie_input[ColName.SE]\n    if prior_file:\n        susie_input['SNPVAR'] = susie_input['SNPVAR'] / susie_input['SNPVAR'].sum()\n    else:\n        susie_input['SNPVAR'] = 1 / len(susie_input)\n    susie_input[[ColName.SNPID, ColName.Z]].to_csv(f\"{temp_dir}/susie.input\", sep=\" \", index=False, header=True)\n\n    import rpy2.robjects as ro\n    from rpy2.rinterface_lib.callbacks import logger as rpy2_logger\n\n    rpy2_logger.setLevel(logging.ERROR)\n\n    ro.r(\n        f'''library('data.table')\n            ld = fread('{ld_matrix}', sep=' ', header=FALSE)\n            ld = as.matrix(ld)\n            df = fread('{temp_dir}/susie.input', sep=' ', header=TRUE)\n            z = df$Z\n            prior = df$SNPVAR\n            library('susieR')\n            res = susie_rss(z, ld, n={sample_size}, L = {max_causal})\n            pip = res$pip'''\n    )\n    susie_input['pip'] = ro.r('pip')\n    susie_res = pd.Series(susie_input['pip'].values, index=susie_input[ColName.SNPID].tolist())\n    return susie_res\n</code></pre>"},{"location":"api/tools/","title":"Tools","text":"<p>check if tools are installed and return their path.</p> Source code in <code>easyfinemap/tools.py</code> <pre><code>def __init__(self):\n\"\"\"Initialize.\"\"\"\n    self.logger = logging.getLogger(\"Tools\")\n</code></pre>"},{"location":"api/tools/#easyfinemap.tools.Tools.bcftools","title":"<code>bcftools</code>  <code>property</code>","text":"<p>Check if bcftools is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.caviarbf","title":"<code>caviarbf</code>  <code>property</code>","text":"<p>Check if caviarbf is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.finemap","title":"<code>finemap</code>  <code>property</code>","text":"<p>Check if finemap is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.gcta","title":"<code>gcta</code>  <code>property</code>","text":"<p>Check if gcta is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.model_search","title":"<code>model_search</code>  <code>property</code>","text":"<p>Check if model_search is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.paintor","title":"<code>paintor</code>  <code>property</code>","text":"<p>Check if paintor is installed.</p>"},{"location":"api/tools/#easyfinemap.tools.Tools.plink","title":"<code>plink</code>  <code>property</code>","text":"<p>Check if plink is installed.</p>"},{"location":"api/utils/","title":"utils","text":"<p>Utils for easyfinemap.</p>"},{"location":"api/utils/#easyfinemap.utils.get_significant_snps","title":"<code>get_significant_snps(df, pvalue_threshold=5e-08, use_most_sig_if_no_sig=True)</code>","text":"<p>Get the significant snps from the input file, filter by pvalue.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>The input summary statistics.</p> required <code>pvalue_threshold</code> <code>float</code> <p>The pvalue threshold, by default 5e-8</p> <code>5e-08</code> <code>use_most_sig_if_no_sig</code> <code>bool</code> <p>Whether to use the most significant SNP if no significant SNP found, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The significant snps, sorted by pvalue.</p> Source code in <code>easyfinemap/utils.py</code> <pre><code>def get_significant_snps(df: pd.DataFrame, pvalue_threshold: float = 5e-8, use_most_sig_if_no_sig: bool = True):\n\"\"\"\n    Get the significant snps from the input file, filter by pvalue.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The input summary statistics.\n    pvalue_threshold : float, optional\n        The pvalue threshold, by default 5e-8\n    use_most_sig_if_no_sig : bool, optional\n        Whether to use the most significant SNP if no significant SNP found, by default True\n\n    Returns\n    -------\n    pd.DataFrame\n        The significant snps, sorted by pvalue.\n    \"\"\"\n    sig_df = df.loc[df[ColName.P] &lt; pvalue_threshold].copy()\n    if sig_df.empty:\n        if use_most_sig_if_no_sig:\n            sig_df = df.loc[df[ColName.P] == df[ColName.P].min()].copy()\n            logging.debug(f\"Use the most significant SNP: {sig_df[ColName.SNPID].values[0]}\")\n            logging.debug(f\"pvalue: {sig_df[ColName.P].values[0]}\")\n        else:\n            raise ValueError(\"No significant SNPs found.\")\n    else:\n        sig_df.sort_values(ColName.P, inplace=True)\n        sig_df.reset_index(drop=True, inplace=True)\n    return sig_df\n</code></pre>"},{"location":"api/utils/#easyfinemap.utils.io_in_tempdir","title":"<code>io_in_tempdir(dir='./tmp')</code>","text":"<p>Make tempdir for process.</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>The tempdir, by default './tmp'</p> <code>'./tmp'</code> <p>Returns:</p> Type Description <code>decorator</code> <p>The decorator of io in tempdir.</p> Source code in <code>easyfinemap/utils.py</code> <pre><code>def io_in_tempdir(dir='./tmp'):\n\"\"\"\n    Make tempdir for process.\n\n    Parameters\n    ----------\n    dir : str, optional\n        The tempdir, by default './tmp'\n\n    Returns\n    -------\n    decorator\n        The decorator of io in tempdir.\n    \"\"\"\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            temp_dir = tempfile.mkdtemp(dir=dir)\n            logger = logging.getLogger(\"IO\")\n            logger.debug(f\"Tempdir: {temp_dir}\")\n            try:\n                result = func(*args, temp_dir=temp_dir, **kwargs)\n            except Exception:\n                raise\n            else:\n                if logging.getLogger().getEffectiveLevel() &gt;= logging.INFO:\n                    shutil.rmtree(temp_dir)\n                pass\n            return result  # type: ignore\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/utils/#easyfinemap.utils.make_SNPID_unique","title":"<code>make_SNPID_unique(sumstat, replace_rsIDcol=False, remove_duplicates=True)</code>","text":"<p>Make the SNPID unique.</p> <p>The unique SNPID is chr-bp-sorted(EA,NEA)</p> <p>Parameters:</p> Name Type Description Default <code>sumstat</code> <code>DataFrame</code> <p>The input summary statistics.</p> required <code>replace_rsIDcol</code> <code>bool</code> <p>Whether to replace the rsID column with the unique SNPID, by default False</p> <code>False</code> <code>remove_duplicates</code> <code>bool</code> <p>Whether to remove the duplicated SNPs, keep the one with smallest P-value, by default True</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The summary statistics with unique SNPID.</p> Source code in <code>easyfinemap/utils.py</code> <pre><code>def make_SNPID_unique(sumstat: pd.DataFrame, replace_rsIDcol: bool = False, remove_duplicates: bool = True):\n\"\"\"\n    Make the SNPID unique.\n\n    The unique SNPID is chr-bp-sorted(EA,NEA)\n\n    Parameters\n    ----------\n    sumstat : pd.DataFrame\n        The input summary statistics.\n    replace_rsIDcol : bool, optional\n        Whether to replace the rsID column with the unique SNPID, by default False\n    remove_duplicates : bool, optional\n        Whether to remove the duplicated SNPs, keep the one with smallest P-value, by default True\n\n    Returns\n    -------\n    pd.DataFrame\n        The summary statistics with unique SNPID.\n    \"\"\"\n    df = sumstat.copy()\n    allele_df = df[[ColName.EA, ColName.NEA]].copy()\n    b = allele_df.values\n    b.sort(axis=1)\n    allele_df[[ColName.EA, ColName.NEA]] = b\n    allele_df[ColName.SNPID] = (\n        df[ColName.CHR].astype(str)\n        + \"-\"\n        + df[ColName.BP].astype(str)\n        + \"-\"\n        + allele_df[ColName.EA]\n        + \"-\"\n        + allele_df[ColName.NEA]\n    )\n    if replace_rsIDcol:\n        df[ColName.RSID] = allele_df[ColName.SNPID]\n    else:\n        if ColName.SNPID in df.columns:\n            df.drop(ColName.SNPID, axis=1, inplace=True)\n        df.insert(loc=0, column=ColName.SNPID, value=allele_df[ColName.SNPID].values)  # type: ignore\n    if remove_duplicates:\n        df.sort_values(ColName.P, inplace=True)\n        if replace_rsIDcol:\n            df.drop_duplicates(subset=[ColName.RSID], keep=\"first\", inplace=True)\n        else:\n            df.drop_duplicates(subset=[ColName.SNPID], keep=\"first\", inplace=True)\n        df.sort_values([ColName.CHR, ColName.BP], inplace=True)\n        df.reset_index(drop=True, inplace=True)\n    return df\n</code></pre>"}]}